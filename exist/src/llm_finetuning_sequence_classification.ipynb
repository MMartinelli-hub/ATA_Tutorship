{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7acbaa10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup data directory if needed\n",
    "import os\n",
    "if not os.path.exists('../data'):\n",
    "    !mkdir ../data\n",
    "    print(\"Created data directory\")\n",
    "else:\n",
    "    print(\"Data directory exists\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29856497",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfcdb833",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install Unsloth and dependencies\n",
    "%%capture\n",
    "import os, re\n",
    "if \"COLAB_\" not in \"\".join(os.environ.keys()):\n",
    "    !pip install unsloth\n",
    "else:\n",
    "    import torch; v = re.match(r\"[0-9\\.]{3,}\", str(torch.__version__)).group(0)\n",
    "    xformers = \"xformers==\" + (\"0.0.32.post2\" if v == \"2.8.0\" else \"0.0.29.post3\")\n",
    "    !pip install --no-deps bitsandbytes accelerate {xformers} peft trl triton cut_cross_entropy unsloth_zoo\n",
    "    !pip install sentencepiece protobuf \"datasets>=3.4.1,<4.0.0\" \"huggingface_hub>=0.34.0\" hf_transfer\n",
    "    !pip install --no-deps unsloth\n",
    "!pip install transformers==4.56.2\n",
    "!pip install --no-deps trl==0.22.2\n",
    "\n",
    "print(\"✓ Unsloth and dependencies installed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4433b20d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_recall_fscore_support,\n",
    "    classification_report,\n",
    "    confusion_matrix\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "\n",
    "print(\"✓ Libraries imported\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8fcc56",
   "metadata": {},
   "source": [
    "## Load Base Model with Unsloth\n",
    "\n",
    "Load Gemma-3-4B model with 4-bit quantization for efficient fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d09c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unsloth import FastModel\n",
    "import torch\n",
    "\n",
    "# Load Gemma-3-4B model with 4-bit quantization\n",
    "model, tokenizer = FastModel.from_pretrained(\n",
    "    model_name = \"unsloth/gemma-3-4b-it\",\n",
    "    max_seq_length = 2048,\n",
    "    load_in_4bit = True,\n",
    "    load_in_8bit = False,\n",
    "    full_finetuning = False,\n",
    ")\n",
    "\n",
    "print(\"✓ Gemma-3-4B model loaded\")\n",
    "print(f\"  Model: {model.__class__.__name__}\")\n",
    "print(f\"  Max sequence length: 2048\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2877761d",
   "metadata": {},
   "source": [
    "## Add LoRA Adapters\n",
    "\n",
    "Configure LoRA (Low-Rank Adaptation) for parameter-efficient fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f131416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add LoRA adapters for efficient fine-tuning\n",
    "model = FastModel.get_peft_model(\n",
    "    model,\n",
    "    finetune_vision_layers     = False,\n",
    "    finetune_language_layers   = True,\n",
    "    finetune_attention_modules = True,\n",
    "    finetune_mlp_modules       = True,\n",
    "    r = 16,\n",
    "    lora_alpha = 16,\n",
    "    lora_dropout = 0,\n",
    "    bias = \"none\",\n",
    "    random_state = 3407,\n",
    ")\n",
    "\n",
    "print(\"✓ LoRA adapters configured\")\n",
    "print(f\"  Rank (r): 16\")\n",
    "print(f\"  Alpha: 16\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a87d50",
   "metadata": {},
   "source": [
    "## Data Loading and Processing\n",
    "\n",
    "Load EXIST English-only dataset and format for classification task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e7e167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure chat template for Gemma-3\n",
    "from unsloth.chat_templates import get_chat_template\n",
    "\n",
    "tokenizer = get_chat_template(\n",
    "    tokenizer,\n",
    "    chat_template = \"gemma-3\",\n",
    ")\n",
    "\n",
    "print(\"✓ Gemma-3 chat template configured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b42e0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load EXIST dataset (English only)\n",
    "df = pd.read_csv('../data/aggregated_data_en.csv')\n",
    "\n",
    "print(f\"✓ Data loaded\")\n",
    "print(f\"  Total samples: {len(df)}\")\n",
    "print(f\"\\nSplit distribution:\")\n",
    "print(df['split'].value_counts())\n",
    "print(f\"\\nLabel distribution:\")\n",
    "print(df['label_sexist'].value_counts())\n",
    "\n",
    "# Show example\n",
    "print(f\"\\nExample:\")\n",
    "print(f\"  Text: {df.iloc[0]['text']}\")\n",
    "print(f\"  Label: {df.iloc[0]['label_sexist']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a90f831e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data\n",
    "train_df = df[df['split'] == 'train'].copy()\n",
    "dev_df = df[df['split'] == 'dev'].copy()\n",
    "test_df = df[df['split'] == 'test'].copy()\n",
    "\n",
    "print(f\"Train: {len(train_df)} samples\")\n",
    "print(f\"Dev: {len(dev_df)} samples\")\n",
    "print(f\"Test: {len(test_df)} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c9e5ac",
   "metadata": {},
   "source": [
    "## Format Data for Classification\n",
    "\n",
    "Convert EXIST data to conversation format for fine-tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bef1ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to conversation format for fine-tuning\n",
    "from datasets import Dataset\n",
    "\n",
    "conversations = []\n",
    "for _, row in train_df.iterrows():\n",
    "    text = row['text']\n",
    "    label = row['label_sexist']\n",
    "    \n",
    "    # Format as instruction-response pairs\n",
    "    conversation = [\n",
    "        {\"role\": \"user\", \"content\": f\"Classify this tweet as 'sexist' or 'not sexist': {text}\"},\n",
    "        {\"role\": \"assistant\", \"content\": label}\n",
    "    ]\n",
    "    conversations.append({\"conversations\": conversation})\n",
    "\n",
    "# Create dataset\n",
    "dataset = Dataset.from_list(conversations)\n",
    "\n",
    "print(f\"✓ Dataset formatted for fine-tuning\")\n",
    "print(f\"  Total examples: {len(dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a80b74",
   "metadata": {},
   "source": [
    "### Example Training Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a29085",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show example conversation\n",
    "print(\"Example training conversation:\")\n",
    "print(dataset[100]['conversations'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf94a44f",
   "metadata": {},
   "source": [
    "## Apply Chat Template\n",
    "\n",
    "Apply Gemma-3 chat template to format conversations for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8df9b032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply chat template to conversations\n",
    "def formatting_prompts_func(examples):\n",
    "    convos = examples[\"conversations\"]\n",
    "    texts = [\n",
    "        tokenizer.apply_chat_template(\n",
    "            convo,\n",
    "            tokenize=False,\n",
    "            add_generation_prompt=False\n",
    "        ).removeprefix('<bos>')\n",
    "        for convo in convos\n",
    "    ]\n",
    "    return {\"text\": texts}\n",
    "\n",
    "dataset = dataset.map(formatting_prompts_func, batched=True)\n",
    "\n",
    "print(\"✓ Chat template applied to dataset\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3b76d0",
   "metadata": {},
   "source": [
    "### Formatted Training Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60f47a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show formatted text\n",
    "print(\"Formatted training example:\")\n",
    "print(dataset[100][\"text\"][:400] + \"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65f58c4",
   "metadata": {},
   "source": [
    "## Configure Training\n",
    "\n",
    "Set up training arguments and trainer with response masking."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d400ddc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure trainer\n",
    "from trl import SFTTrainer, SFTConfig\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    train_dataset = dataset,\n",
    "    eval_dataset = None,\n",
    "    args = SFTConfig(\n",
    "        dataset_text_field = \"text\",\n",
    "        per_device_train_batch_size = 2,\n",
    "        gradient_accumulation_steps = 4,\n",
    "        warmup_steps = 5,\n",
    "        num_train_epochs = 1,  # Full training run\n",
    "        learning_rate = 2e-4,\n",
    "        logging_steps = 10,\n",
    "        optim = \"adamw_8bit\",\n",
    "        weight_decay = 0.01,\n",
    "        lr_scheduler_type = \"linear\",\n",
    "        seed = 3407,\n",
    "        output_dir = \"outputs\",\n",
    "        report_to = \"none\",\n",
    "    ),\n",
    ")\n",
    "\n",
    "print(\"✓ Trainer configured\")\n",
    "print(f\"  Epochs: 1\")\n",
    "print(f\"  Batch size: 2\")\n",
    "print(f\"  Learning rate: 2e-4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8f6657",
   "metadata": {},
   "source": [
    "### Enable Response-Only Training\n",
    "\n",
    "Train only on model responses, not user inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c52c8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train only on assistant responses\n",
    "from unsloth.chat_templates import train_on_responses_only\n",
    "\n",
    "trainer = train_on_responses_only(\n",
    "    trainer,\n",
    "    instruction_part = \"<start_of_turn>user\\n\",\n",
    "    response_part = \"<start_of_turn>model\\n\",\n",
    ")\n",
    "\n",
    "print(\"✓ Response-only training enabled\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ecbfc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check initial memory usage\n",
    "gpu_stats = torch.cuda.get_device_properties(0)\n",
    "start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
    "max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n",
    "\n",
    "print(f\"GPU: {gpu_stats.name}\")\n",
    "print(f\"Max memory: {max_memory} GB\")\n",
    "print(f\"Reserved: {start_gpu_memory} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b139b145",
   "metadata": {},
   "source": [
    "## Train the Model\n",
    "\n",
    "Note: Training may take several hours depending on hardware."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaedc877",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start training\n",
    "print(\"=\"*60)\n",
    "print(\"Starting fine-tuning...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "trainer_stats = trainer.train()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"✓ TRAINING COMPLETED!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9b7f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show training statistics\n",
    "used_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
    "used_memory_for_lora = round(used_memory - start_gpu_memory, 3)\n",
    "training_time_minutes = round(trainer_stats.metrics['train_runtime']/60, 2)\n",
    "\n",
    "print(f\"Training time: {training_time_minutes} minutes\")\n",
    "print(f\"Peak memory: {used_memory} GB\")\n",
    "print(f\"Memory for training: {used_memory_for_lora} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32f9f9a8",
   "metadata": {},
   "source": [
    "## Save Fine-Tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdac9e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save LoRA adapters\n",
    "model.save_pretrained(\"models/gemma3_sexism_classifier\")\n",
    "tokenizer.save_pretrained(\"models/gemma3_sexism_classifier\")\n",
    "\n",
    "print(\"✓ Model saved to models/gemma3_sexism_classifier\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed38f507",
   "metadata": {},
   "source": [
    "## Inference and Evaluation\n",
    "\n",
    "Run predictions on test set and evaluate with classification metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2508bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare test data for evaluation\n",
    "test_texts = test_df['text'].tolist()\n",
    "test_labels = test_df['label_sexist'].tolist()\n",
    "\n",
    "print(f\"✓ Test set prepared: {len(test_texts)} samples\")\n",
    "print(f\"\\nLabel distribution in test set:\")\n",
    "print(test_df['label_sexist'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "273073da",
   "metadata": {},
   "source": [
    "## Run Predictions on Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b2483e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run inference on test set\n",
    "print(\"Running predictions on test set...\")\n",
    "\n",
    "predictions = []\n",
    "for i, text in enumerate(tqdm(test_texts, desc=\"Classifying\")):\n",
    "    # Create prompt with proper format for Gemma-3\n",
    "    prompt = f\"Classify this tweet as 'sexist' or 'not sexist': {text}\"\n",
    "    \n",
    "    # Format as conversation\n",
    "    conversation = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    \n",
    "    # Apply chat template and tokenize\n",
    "    formatted_prompt = tokenizer.apply_chat_template(\n",
    "        conversation,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True\n",
    "    )\n",
    "    \n",
    "    # Tokenize\n",
    "    inputs = tokenizer(formatted_prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "    \n",
    "    # Generate\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=10,  # Short response for classification\n",
    "        temperature=0.3,  # Lower temperature for more deterministic output\n",
    "        top_p=0.95,\n",
    "        top_k=40,\n",
    "    )\n",
    "    \n",
    "    # Decode and parse\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True).lower()\n",
    "    \n",
    "    # Extract label from response\n",
    "    # Look for the assistant's response after the prompt\n",
    "    if \"sexist\" in response:\n",
    "        if \"not sexist\" in response or \"non-sexist\" in response:\n",
    "            predicted_label = \"not sexist\"\n",
    "        else:\n",
    "            predicted_label = \"sexist\"\n",
    "    else:\n",
    "        predicted_label = \"not sexist\"  # Default fallback\n",
    "    \n",
    "    predictions.append(predicted_label)\n",
    "\n",
    "print(f\"\\n✓ Predictions completed: {len(predictions)} predictions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a10d8389",
   "metadata": {},
   "source": [
    "## Evaluate Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46fdf9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metrics\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "    test_labels, predictions, average='weighted'\n",
    ")\n",
    "acc = accuracy_score(test_labels, predictions)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"FINE-TUNED LLM RESULTS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nTest Set Performance:\")\n",
    "print(f\"  Accuracy:  {acc:.4f}\")\n",
    "print(f\"  Precision: {precision:.4f}\")\n",
    "print(f\"  Recall:    {recall:.4f}\")\n",
    "print(f\"  F1 Score:  {f1:.4f}\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Detailed classification report\n",
    "print(\"\\nDetailed Classification Report:\")\n",
    "print(\"-\" * 60)\n",
    "print(classification_report(test_labels, predictions, \n",
    "                          target_names=['not sexist', 'sexist']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac2c9311",
   "metadata": {},
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345bc472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "cm = confusion_matrix(test_labels, predictions, labels=['not sexist', 'sexist'])\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=['not sexist', 'sexist'],\n",
    "            yticklabels=['not sexist', 'sexist'])\n",
    "plt.ylabel('True Label')\n",
    "plt.xlabel('Predicted Label')\n",
    "plt.title('Confusion Matrix - Fine-Tuned Gemma-3-4B')\n",
    "plt.tight_layout()\n",
    "plt.savefig('confusion_matrix_finetuned.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"✓ Confusion matrix saved to 'confusion_matrix_finetuned.png'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff60394",
   "metadata": {},
   "source": [
    "## Save Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e01077e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predictions to CSV\n",
    "output_df = test_df.copy()\n",
    "output_df['predicted_label'] = predictions\n",
    "output_df['correct'] = output_df['label_sexist'] == output_df['predicted_label']\n",
    "\n",
    "output_df.to_csv('predictions_finetuned_gemma3.csv', index=False)\n",
    "print(\"✓ Predictions saved to 'predictions_finetuned_gemma3.csv'\")\n",
    "\n",
    "# Show accuracy\n",
    "print(f\"\\nCorrect predictions: {output_df['correct'].sum()} / {len(output_df)} ({output_df['correct'].mean():.2%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2f44bb",
   "metadata": {},
   "source": [
    "## Example Predictions Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678415a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show example predictions\n",
    "print(\"Example Predictions:\")\n",
    "print(\"=\"*100)\n",
    "\n",
    "# Correct predictions - sexist\n",
    "print(\"\\n✓ CORRECT PREDICTIONS (Sexist):\")\n",
    "print(\"-\"*100)\n",
    "correct_sexist = output_df[(output_df['correct'] == True) & (output_df['label_sexist'] == 'sexist')]\n",
    "for _, row in correct_sexist.head(3).iterrows():\n",
    "    print(f\"Text: {row['text'][:80]}...\")\n",
    "    print(f\"Label: {row['label_sexist']}\\n\")\n",
    "\n",
    "# Correct predictions - not sexist\n",
    "print(\"\\n✓ CORRECT PREDICTIONS (Not Sexist):\")\n",
    "print(\"-\"*100)\n",
    "correct_not_sexist = output_df[(output_df['correct'] == True) & (output_df['label_sexist'] == 'not sexist')]\n",
    "for _, row in correct_not_sexist.head(3).iterrows():\n",
    "    print(f\"Text: {row['text'][:80]}...\")\n",
    "    print(f\"Label: {row['label_sexist']}\\n\")\n",
    "\n",
    "# Incorrect predictions\n",
    "print(\"\\n✗ INCORRECT PREDICTIONS:\")\n",
    "print(\"-\"*100)\n",
    "incorrect = output_df[output_df['correct'] == False]\n",
    "for _, row in incorrect.head(5).iterrows():\n",
    "    print(f\"Text: {row['text'][:80]}...\")\n",
    "    print(f\"True: {row['label_sexist']:12s} | Predicted: {row['predicted_label']}\\n\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
