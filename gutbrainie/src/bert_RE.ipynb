{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b041a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget -O data.zip https://github.com/MMartinelli-hub/ATA_Tutorship/raw/refs/heads/main/gutbrainie/data/GutBrainIE_Full_Collection_2025.zip\n",
    "!unzip data.zip \"*\"\n",
    "!mkdir data\n",
    "!mv Annotations/ ./data\n",
    "!mv Articles/ ./data\n",
    "!mv Test_Data/ ./data\n",
    "!rm -rf data.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58b820ce",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bef401a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModel,\n",
    "    TrainingArguments,\n",
    "    Trainer\n",
    ")\n",
    "from torch.utils.data import Dataset\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(SEED)\n",
    "\n",
    "print(\"Setup complete\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a349db",
   "metadata": {},
   "source": [
    "## Define Relation Labels and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1280da2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define legal relation predicates\n",
    "RELATION_LABELS = [\n",
    "    \"no relation\",  # For negative samples\n",
    "    \"administered\",\n",
    "    \"affect\",\n",
    "    \"change abundance\",\n",
    "    \"change effect\",\n",
    "    \"change expression\",\n",
    "    \"compared to\",\n",
    "    \"impact\",\n",
    "    \"influence\",\n",
    "    \"interact\",\n",
    "    \"is a\",\n",
    "    \"is linked to\",\n",
    "    \"located in\",\n",
    "    \"part of\",\n",
    "    \"produced by\",\n",
    "    \"strike\",\n",
    "    \"target\",\n",
    "    \"used by\"\n",
    "]\n",
    "\n",
    "label2id = {label: idx for idx, label in enumerate(RELATION_LABELS)}\n",
    "id2label = {idx: label for idx, label in enumerate(RELATION_LABELS)}\n",
    "\n",
    "print(f\"Total relation labels: {len(RELATION_LABELS)}\")\n",
    "print(f\"Labels: {RELATION_LABELS}\")\n",
    "\n",
    "# Define legal entity type relations (subject_label, predicate, object_label)\n",
    "# Order matters: relation is from subject to object\n",
    "LEGAL_RELATIONS = [\n",
    "    (\"DDF\", \"affect\", \"DDF\"),\n",
    "    (\"microbiome\", \"is linked to\", \"DDF\"),\n",
    "    (\"DDF\", \"target\", \"human\"),\n",
    "    (\"drug\", \"change effect\", \"DDF\"),\n",
    "    (\"DDF\", \"is a\", \"DDF\"),\n",
    "    (\"microbiome\", \"located in\", \"human\"),\n",
    "    (\"chemical\", \"influence\", \"DDF\"),\n",
    "    (\"dietary supplement\", \"influence\", \"DDF\"),\n",
    "    (\"DDF\", \"target\", \"animal\"),\n",
    "    (\"chemical\", \"impact\", \"microbiome\"),\n",
    "    (\"anatomical location\", \"located in\", \"animal\"),\n",
    "    (\"microbiome\", \"located in\", \"animal\"),\n",
    "    (\"chemical\", \"located in\", \"anatomical location\"),\n",
    "    (\"bacteria\", \"part of\", \"microbiome\"),\n",
    "    (\"DDF\", \"strike\", \"anatomical location\"),\n",
    "    (\"drug\", \"administered\", \"animal\"),\n",
    "    (\"bacteria\", \"influence\", \"DDF\"),\n",
    "    (\"drug\", \"impact\", \"microbiome\"),\n",
    "    (\"DDF\", \"change abundance\", \"microbiome\"),\n",
    "    (\"microbiome\", \"located in\", \"anatomical location\"),\n",
    "    (\"microbiome\", \"used by\", \"biomedical technique\"),\n",
    "    (\"chemical\", \"produced by\", \"microbiome\"),\n",
    "    (\"dietary supplement\", \"impact\", \"microbiome\"),\n",
    "    (\"bacteria\", \"located in\", \"animal\"),\n",
    "    (\"animal\", \"used by\", \"biomedical technique\"),\n",
    "    (\"chemical\", \"impact\", \"bacteria\"),\n",
    "    (\"chemical\", \"located in\", \"animal\"),\n",
    "    (\"food\", \"impact\", \"bacteria\"),\n",
    "    (\"microbiome\", \"compared to\", \"microbiome\"),\n",
    "    (\"human\", \"used by\", \"biomedical technique\"),\n",
    "    (\"bacteria\", \"change expression\", \"gene\"),\n",
    "    (\"chemical\", \"located in\", \"human\"),\n",
    "    (\"drug\", \"interact\", \"chemical\"),\n",
    "    (\"food\", \"administered\", \"human\"),\n",
    "    (\"DDF\", \"change abundance\", \"bacteria\"),\n",
    "    (\"chemical\", \"interact\", \"chemical\"),\n",
    "    (\"chemical\", \"part of\", \"chemical\"),\n",
    "    (\"dietary supplement\", \"impact\", \"bacteria\"),\n",
    "    (\"DDF\", \"interact\", \"chemical\"),\n",
    "    (\"food\", \"impact\", \"microbiome\"),\n",
    "    (\"food\", \"influence\", \"DDF\"),\n",
    "    (\"bacteria\", \"located in\", \"human\"),\n",
    "    (\"dietary supplement\", \"administered\", \"human\"),\n",
    "    (\"bacteria\", \"interact\", \"chemical\"),\n",
    "    (\"drug\", \"change expression\", \"gene\"),\n",
    "    (\"drug\", \"impact\", \"bacteria\"),\n",
    "    (\"drug\", \"administered\", \"human\"),\n",
    "    (\"anatomical location\", \"located in\", \"human\"),\n",
    "    (\"dietary supplement\", \"change expression\", \"gene\"),\n",
    "    (\"chemical\", \"change expression\", \"gene\"),\n",
    "    (\"bacteria\", \"interact\", \"bacteria\"),\n",
    "    (\"drug\", \"interact\", \"drug\"),\n",
    "    (\"microbiome\", \"change expression\", \"gene\"),\n",
    "    (\"bacteria\", \"interact\", \"drug\"),\n",
    "    (\"food\", \"change expression\", \"gene\")\n",
    "]\n",
    "\n",
    "# Create lookup structures for legal relations\n",
    "# Map (subject_label, object_label) -> set of predicates\n",
    "legal_pairs = {}\n",
    "for subj_label, pred, obj_label in LEGAL_RELATIONS:\n",
    "    key = (subj_label, obj_label)\n",
    "    if key not in legal_pairs:\n",
    "        legal_pairs[key] = set()\n",
    "    legal_pairs[key].add(pred)\n",
    "\n",
    "print(f\"\\nTotal legal relation patterns: {len(LEGAL_RELATIONS)}\")\n",
    "print(f\"Total unique entity type pairs: {len(legal_pairs)}\")\n",
    "\n",
    "# Configuration\n",
    "model_name = \"microsoft/BiomedNLP-BiomedBERT-base-uncased-abstract-fulltext\"  # BioBERT for biomedical text\n",
    "output_model_dir = \"models/bert_biomedbert_re\"\n",
    "max_length = 512\n",
    "NEGATIVE_SAMPLE_MULTIPLIER = 10  # Number of negative samples per positive sample\n",
    "\n",
    "print(f\"\\nModel: {model_name}\")\n",
    "print(f\"Output directory: {output_model_dir}\")\n",
    "print(f\"Negative sample multiplier: {NEGATIVE_SAMPLE_MULTIPLIER}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d416ba96",
   "metadata": {},
   "source": [
    "## BERT Model with Entity Markers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f00b85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertForREWithEntityMarkers(nn.Module):\n",
    "    \"\"\"\n",
    "    BERT model for Relation Extraction with entity marker tokens.\n",
    "    \n",
    "    The model extracts hidden states at [E1] and [E2] token positions,\n",
    "    concatenates them, and passes through a classification head.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model_name, num_labels):\n",
    "        super().__init__()\n",
    "        self.bert = AutoModel.from_pretrained(model_name)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        \n",
    "        # Classification head: concatenated entity representations -> labels\n",
    "        hidden_size = self.bert.config.hidden_size\n",
    "        self.classifier = nn.Linear(hidden_size * 2, num_labels)\n",
    "        \n",
    "        self.num_labels = num_labels\n",
    "    \n",
    "    def forward(self, input_ids, attention_mask, e1_mask, e2_mask, labels=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input_ids: Token IDs [batch_size, seq_len]\n",
    "            attention_mask: Attention mask [batch_size, seq_len]\n",
    "            e1_mask: Mask for [E1] token position [batch_size, seq_len]\n",
    "            e2_mask: Mask for [E2] token position [batch_size, seq_len]\n",
    "            labels: Ground truth labels [batch_size]\n",
    "        \"\"\"\n",
    "        # Get BERT outputs\n",
    "        outputs = self.bert(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask\n",
    "        )\n",
    "        \n",
    "        sequence_output = outputs.last_hidden_state  # [batch_size, seq_len, hidden_size]\n",
    "        \n",
    "        # Extract hidden states at [E1] and [E2] positions\n",
    "        # e1_mask and e2_mask are one-hot vectors indicating token positions\n",
    "        e1_h = torch.bmm(e1_mask.unsqueeze(1).float(), sequence_output).squeeze(1)  # [batch_size, hidden_size]\n",
    "        e2_h = torch.bmm(e2_mask.unsqueeze(1).float(), sequence_output).squeeze(1)  # [batch_size, hidden_size]\n",
    "        \n",
    "        # Concatenate entity representations\n",
    "        concat_h = torch.cat([e1_h, e2_h], dim=-1)  # [batch_size, hidden_size * 2]\n",
    "        concat_h = self.dropout(concat_h)\n",
    "        \n",
    "        # Classification\n",
    "        logits = self.classifier(concat_h)  # [batch_size, num_labels]\n",
    "        \n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fct = nn.CrossEntropyLoss()\n",
    "            loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "        \n",
    "        return {\n",
    "            'loss': loss,\n",
    "            'logits': logits\n",
    "        }\n",
    "\n",
    "\n",
    "print(\"BERT RE model class defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d614a1f6",
   "metadata": {},
   "source": [
    "## Data Loading Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505d51c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_re_data(file_paths):\n",
    "    \"\"\"Load relation extraction data from multiple JSON files.\"\"\"\n",
    "    all_data = {}\n",
    "    \n",
    "    for file_path in file_paths:\n",
    "        if os.path.exists(file_path):\n",
    "            with open(file_path, 'r', encoding='utf-8') as f:\n",
    "                data = json.load(f)\n",
    "            all_data.update(data)\n",
    "            print(f\"Loaded {len(data)} documents from {os.path.basename(file_path)}\")\n",
    "        else:\n",
    "            print(f\"Warning: {file_path} not found\")\n",
    "    \n",
    "    return all_data\n",
    "\n",
    "\n",
    "print(\"Data loading function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb88093",
   "metadata": {},
   "source": [
    "## Load Training and Dev Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a20d87ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data from three quality levels\n",
    "train_files = [\n",
    "    \"../data/Annotations/Train/gold_quality/json_format/train_gold.json\",\n",
    "    \"../data/Annotations/Train/platinum_quality/json_format/train_platinum.json\",\n",
    "    \"../data/Annotations/Train/silver_quality/json_format/train_silver.json\"\n",
    "]\n",
    "\n",
    "train_data = load_re_data(train_files)\n",
    "print(f\"\\nTotal training documents: {len(train_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c13a04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dev data\n",
    "dev_data = load_re_data([\"../data/Annotations/Dev/json_format/dev.json\"])\n",
    "print(f\"Total dev documents: {len(dev_data)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aec822f",
   "metadata": {},
   "source": [
    "## Prepare Relation Extraction Examples\n",
    "\n",
    "For each document:\n",
    "1. Extract positive relation examples from annotations\n",
    "2. Generate negative examples by pairing entities that are NOT related\n",
    "3. Apply the negative sample multiplier to balance the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc178cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_full_text_with_offsets(title, abstract):\n",
    "    \"\"\"\n",
    "    Create full text by concatenating title and abstract.\n",
    "    Returns full text and offset for abstract entities.\n",
    "    \"\"\"\n",
    "    full_text = f\"{title} {abstract}\"\n",
    "    abstract_offset = len(title) + 1\n",
    "    return full_text, abstract_offset\n",
    "\n",
    "\n",
    "def adjust_entity_positions(entity, abstract_offset):\n",
    "    \"\"\"\n",
    "    Adjust entity character positions to account for title + abstract concatenation.\n",
    "    \"\"\"\n",
    "    if entity['location'] == 'abstract':\n",
    "        return {\n",
    "            'start_idx': entity['start_idx'] + abstract_offset,\n",
    "            'end_idx': entity['end_idx'] + abstract_offset,\n",
    "            'text_span': entity['text_span'],\n",
    "            'label': entity['label']\n",
    "        }\n",
    "    else:\n",
    "        return {\n",
    "            'start_idx': entity['start_idx'],\n",
    "            'end_idx': entity['end_idx'],\n",
    "            'text_span': entity['text_span'],\n",
    "            'label': entity['label']\n",
    "        }\n",
    "\n",
    "\n",
    "def prepare_re_examples(data, negative_multiplier=1, legal_pairs=None):\n",
    "    \"\"\"\n",
    "    Prepare relation extraction examples with positive and negative samples.\n",
    "    Only considers entity pairs that match legal relation patterns.\n",
    "    \n",
    "    Args:\n",
    "        data: Dictionary of documents with entities and relations\n",
    "        negative_multiplier: Number of negative samples per positive sample\n",
    "        legal_pairs: Dictionary mapping (subject_label, object_label) -> set of predicates\n",
    "    \n",
    "    Returns:\n",
    "        List of examples with text, subject, object, and predicate\n",
    "    \"\"\"\n",
    "    examples = []\n",
    "    \n",
    "    for pmid, article in tqdm(data.items(), desc=\"Preparing RE examples\"):\n",
    "        title = article['metadata']['title']\n",
    "        abstract = article['metadata']['abstract']\n",
    "        full_text, abstract_offset = create_full_text_with_offsets(title, abstract)\n",
    "        \n",
    "        entities = article['entities']\n",
    "        relations = article['relations']\n",
    "        \n",
    "        # Adjust entity positions for full text\n",
    "        adjusted_entities = [adjust_entity_positions(e, abstract_offset) for e in entities]\n",
    "        \n",
    "        # Create positive examples from annotated relations\n",
    "        positive_pairs = set()\n",
    "        for relation in relations:\n",
    "            # Find subject and object entities\n",
    "            subject = None\n",
    "            obj = None\n",
    "            \n",
    "            for entity in adjusted_entities:\n",
    "                if (entity['text_span'] == relation['subject_text_span'] and\n",
    "                    entity['label'] == relation['subject_label']):\n",
    "                    subject = entity\n",
    "                if (entity['text_span'] == relation['object_text_span'] and\n",
    "                    entity['label'] == relation['object_label']):\n",
    "                    obj = entity\n",
    "            \n",
    "            if subject and obj:\n",
    "                examples.append({\n",
    "                    'text': full_text,\n",
    "                    'subject': subject,\n",
    "                    'object': obj,\n",
    "                    'predicate': relation['predicate'],\n",
    "                    'pmid': pmid\n",
    "                })\n",
    "                \n",
    "                # Track positive pairs to avoid generating them as negatives\n",
    "                pair_key = (subject['start_idx'], subject['end_idx'], \n",
    "                           obj['start_idx'], obj['end_idx'])\n",
    "                positive_pairs.add(pair_key)\n",
    "        \n",
    "        # Generate negative examples - only from legal entity type pairs\n",
    "        num_negatives = len(relations) * negative_multiplier\n",
    "        negative_candidates = []\n",
    "        \n",
    "        # Create entity pairs but only for legal entity type combinations\n",
    "        for i, subj in enumerate(adjusted_entities):\n",
    "            for j, obj in enumerate(adjusted_entities):\n",
    "                if i != j:  # Don't create self-relations\n",
    "                    # Check if this entity type pair is legal\n",
    "                    type_pair = (subj['label'], obj['label'])\n",
    "                    if legal_pairs is None or type_pair in legal_pairs:\n",
    "                        pair_key = (subj['start_idx'], subj['end_idx'],\n",
    "                                   obj['start_idx'], obj['end_idx'])\n",
    "                        \n",
    "                        # Only add if not a positive relation\n",
    "                        if pair_key not in positive_pairs:\n",
    "                            negative_candidates.append({\n",
    "                                'text': full_text,\n",
    "                                'subject': subj,\n",
    "                                'object': obj,\n",
    "                                'predicate': 'no relation',\n",
    "                                'pmid': pmid\n",
    "                            })\n",
    "        \n",
    "        # Sample negative examples\n",
    "        if negative_candidates:\n",
    "            num_to_sample = min(num_negatives, len(negative_candidates))\n",
    "            sampled_negatives = random.sample(negative_candidates, num_to_sample)\n",
    "            examples.extend(sampled_negatives)\n",
    "\n",
    "    print(\"RE example preparation function defined\")\n",
    "\n",
    "    return examples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ff0d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare training examples\n",
    "print(\"Preparing training examples...\")\n",
    "train_examples = prepare_re_examples(train_data, negative_multiplier=NEGATIVE_SAMPLE_MULTIPLIER, legal_pairs=legal_pairs)\n",
    "\n",
    "# Count positive vs negative\n",
    "positive_count = sum(1 for ex in train_examples if ex['predicate'] != 'no relation')\n",
    "negative_count = sum(1 for ex in train_examples if ex['predicate'] == 'no relation')\n",
    "\n",
    "print(f\"\\nTraining examples prepared: {len(train_examples)}\")\n",
    "print(f\"  Positive examples: {positive_count}\")\n",
    "print(f\"  Negative examples: {negative_count}\")\n",
    "print(f\"  Ratio (neg/pos): {negative_count/positive_count:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73db99be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare dev examples\n",
    "print(\"Preparing dev examples...\")\n",
    "dev_examples = prepare_re_examples(dev_data, negative_multiplier=NEGATIVE_SAMPLE_MULTIPLIER, legal_pairs=legal_pairs)\n",
    "\n",
    "positive_count_dev = sum(1 for ex in dev_examples if ex['predicate'] != 'no relation')\n",
    "negative_count_dev = sum(1 for ex in dev_examples if ex['predicate'] == 'no relation')\n",
    "\n",
    "print(f\"\\nDev examples prepared: {len(dev_examples)}\")\n",
    "print(f\"  Positive examples: {positive_count_dev}\")\n",
    "print(f\"  Negative examples: {negative_count_dev}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb2c993",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show example\n",
    "print(\"\\nExample training instance:\")\n",
    "example = train_examples[0]\n",
    "print(f\"  Text: {example['text'][:150]}...\")\n",
    "print(f\"  Subject: '{example['subject']['text_span']}' [{example['subject']['label']}]\")\n",
    "print(f\"  Object: '{example['object']['text_span']}' [{example['object']['label']}]\")\n",
    "print(f\"  Predicate: {example['predicate']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68122b4",
   "metadata": {},
   "source": [
    "## Initialize Tokenizer and Add Special Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "283b9d86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize tokenizer\n",
    "print(\"Initializing tokenizer...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, use_fast=True)\n",
    "\n",
    "# Add special entity marker tokens\n",
    "special_tokens = {\"additional_special_tokens\": [\"[E1]\", \"[/E1]\", \"[E2]\", \"[/E2]\"]}\n",
    "tokenizer.add_special_tokens(special_tokens)\n",
    "\n",
    "# Get token IDs for entity markers\n",
    "e1_token_id = tokenizer.convert_tokens_to_ids(\"[E1]\")\n",
    "e2_token_id = tokenizer.convert_tokens_to_ids(\"[E2]\")\n",
    "\n",
    "print(f\"Tokenizer loaded: {tokenizer.__class__.__name__}\")\n",
    "print(f\"  Vocabulary size (with special tokens): {len(tokenizer)}\")\n",
    "print(f\"  [E1] token ID: {e1_token_id}\")\n",
    "print(f\"  [E2] token ID: {e2_token_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27b4ee4",
   "metadata": {},
   "source": [
    "## Tokenization with Entity Markers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d859ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_entity_markers(text, subject, obj):\n",
    "    \"\"\"\n",
    "    Insert entity marker tokens around subject and object entities.\n",
    "    \n",
    "    Args:\n",
    "        text: Full text\n",
    "        subject: Subject entity dict with start_idx, end_idx\n",
    "        obj: Object entity dict with start_idx, end_idx\n",
    "    \n",
    "    Returns:\n",
    "        Text with markers inserted\n",
    "    \"\"\"\n",
    "    # Sort entities by position to insert markers correctly\n",
    "    entities = [(subject['start_idx'], subject['end_idx'], '[E1]', '[/E1]'),\n",
    "                (obj['start_idx'], obj['end_idx'], '[E2]', '[/E2]')]\n",
    "    entities = sorted(entities, key=lambda x: x[0])\n",
    "    \n",
    "    # Insert markers from right to left to maintain positions\n",
    "    marked_text = text\n",
    "    offset = 0\n",
    "    \n",
    "    for start, end, start_marker, end_marker in entities:\n",
    "        # Adjust positions with offset\n",
    "        adj_start = start + offset\n",
    "        adj_end = end + offset + 1  # +1 because end_idx is inclusive\n",
    "        \n",
    "        # Insert markers\n",
    "        marked_text = (marked_text[:adj_start] + start_marker + \n",
    "                      marked_text[adj_start:adj_end] + end_marker + \n",
    "                      marked_text[adj_end:])\n",
    "        \n",
    "        # Update offset\n",
    "        offset += len(start_marker) + len(end_marker)\n",
    "    \n",
    "    return marked_text\n",
    "\n",
    "\n",
    "def tokenize_re_example(example, tokenizer, e1_token_id, e2_token_id, max_length=512):\n",
    "    \"\"\"\n",
    "    Tokenize a relation extraction example with entity markers.\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with input_ids, attention_mask, e1_mask, e2_mask, and label\n",
    "    \"\"\"\n",
    "    # Insert entity markers\n",
    "    marked_text = insert_entity_markers(\n",
    "        example['text'],\n",
    "        example['subject'],\n",
    "        example['object']\n",
    "    )\n",
    "    \n",
    "    # Tokenize\n",
    "    encoding = tokenizer(\n",
    "        marked_text,\n",
    "        truncation=True,\n",
    "        max_length=max_length,\n",
    "        padding='max_length',\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    \n",
    "    input_ids = encoding['input_ids'].squeeze(0)\n",
    "    attention_mask = encoding['attention_mask'].squeeze(0)\n",
    "    \n",
    "    # Create masks for [E1] and [E2] positions\n",
    "    e1_mask = (input_ids == e1_token_id).long()\n",
    "    e2_mask = (input_ids == e2_token_id).long()\n",
    "    \n",
    "    # Get label\n",
    "    label = label2id[example['predicate']]\n",
    "    \n",
    "    return {\n",
    "        'input_ids': input_ids,\n",
    "        'attention_mask': attention_mask,\n",
    "        'e1_mask': e1_mask,\n",
    "        'e2_mask': e2_mask,\n",
    "        'labels': torch.tensor(label, dtype=torch.long)\n",
    "    }\n",
    "\n",
    "\n",
    "print(\"Tokenization functions defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9d984c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test tokenization\n",
    "test_example = train_examples[0]\n",
    "tokenized = tokenize_re_example(test_example, tokenizer, e1_token_id, e2_token_id)\n",
    "\n",
    "print(\"Test tokenization:\")\n",
    "print(f\"  Input IDs shape: {tokenized['input_ids'].shape}\")\n",
    "print(f\"  E1 mask sum (should be 1): {tokenized['e1_mask'].sum().item()}\")\n",
    "print(f\"  E2 mask sum (should be 1): {tokenized['e2_mask'].sum().item()}\")\n",
    "print(f\"  Label: {tokenized['labels'].item()} ({id2label[tokenized['labels'].item()]})\")\n",
    "\n",
    "# Show marked text\n",
    "marked = insert_entity_markers(test_example['text'], test_example['subject'], test_example['object'])\n",
    "print(f\"\\nMarked text preview: {marked[:200]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d763b3",
   "metadata": {},
   "source": [
    "## Create Dataset Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d379f5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class REDataset(Dataset):\n",
    "    \"\"\"Custom dataset for Relation Extraction.\"\"\"\n",
    "    \n",
    "    def __init__(self, examples, tokenizer, e1_token_id, e2_token_id, max_length=512):\n",
    "        self.examples = examples\n",
    "        self.tokenizer = tokenizer\n",
    "        self.e1_token_id = e1_token_id\n",
    "        self.e2_token_id = e2_token_id\n",
    "        self.max_length = max_length\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.examples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        example = self.examples[idx]\n",
    "        return tokenize_re_example(\n",
    "            example,\n",
    "            self.tokenizer,\n",
    "            self.e1_token_id,\n",
    "            self.e2_token_id,\n",
    "            self.max_length\n",
    "        )\n",
    "\n",
    "\n",
    "print(\"Dataset class defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3a9c3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets\n",
    "print(\"Creating datasets...\")\n",
    "train_dataset = REDataset(train_examples, tokenizer, e1_token_id, e2_token_id, max_length)\n",
    "dev_dataset = REDataset(dev_examples, tokenizer, e1_token_id, e2_token_id, max_length)\n",
    "\n",
    "print(f\"Training dataset: {len(train_dataset)} examples\")\n",
    "print(f\"Dev dataset: {len(dev_dataset)} examples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7439fb",
   "metadata": {},
   "source": [
    "## Initialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b8c77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize model\n",
    "print(\"Initializing BERT RE model...\")\n",
    "model = BertForREWithEntityMarkers(model_name, num_labels=len(RELATION_LABELS))\n",
    "\n",
    "# Resize token embeddings to account for new special tokens\n",
    "model.bert.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "print(f\"Model initialized\")\n",
    "print(f\"  Number of labels: {model.num_labels}\")\n",
    "print(f\"  Hidden size: {model.bert.config.hidden_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a057905",
   "metadata": {},
   "source": [
    "## Custom Trainer for Entity Marker Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5b5045f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RETrainer(Trainer):\n",
    "    \"\"\"Custom Trainer that handles entity marker masks.\"\"\"\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        outputs = model(**inputs, labels=labels)\n",
    "        loss = outputs['loss']\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "\n",
    "print(\"Custom trainer class defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e63441a",
   "metadata": {},
   "source": [
    "## Configure Training Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafb9a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_model_dir,\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"eval_loss\",\n",
    "    push_to_hub=False,\n",
    "    logging_steps=100,\n",
    "    save_total_limit=2,\n",
    "    seed=SEED,\n",
    "    fp16=torch.cuda.is_available(),\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "print(\"Training configuration ready\")\n",
    "print(f\"  Batch size: {training_args.per_device_train_batch_size}\")\n",
    "print(f\"  Epochs: {training_args.num_train_epochs}\")\n",
    "print(f\"  Learning rate: {training_args.learning_rate}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85aa789",
   "metadata": {},
   "source": [
    "## Train Model\n",
    "\n",
    "**Note:** This cell might take several minutes to hours depending on dataset size and hardware.\n",
    "\n",
    "**Hyperparameters to experiment with:**\n",
    "- `NEGATIVE_SAMPLE_MULTIPLIER`: Try 1, 2, 3, 5\n",
    "- `learning_rate`: Try 1e-5, 2e-5, 3e-5\n",
    "- `num_train_epochs`: Try 3, 5, 10\n",
    "- `per_device_train_batch_size`: Adjust based on GPU memory\n",
    "- Different pretrained models: \"allenai/scibert_scivocab_uncased\", \"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7254bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize trainer\n",
    "print(\"Initializing Trainer...\")\n",
    "trainer = RETrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=dev_dataset\n",
    ")\n",
    "\n",
    "print(\"Trainer initialized\")\n",
    "print(f\"  Training samples: {len(train_dataset)}\")\n",
    "print(f\"  Evaluation samples: {len(dev_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0397f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start training\n",
    "print(\"=\"*60)\n",
    "print(\"Starting model training...\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "import time\n",
    "training_start_time = time.time()\n",
    "\n",
    "train_result = trainer.train()\n",
    "\n",
    "training_duration = time.time() - training_start_time\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TRAINING COMPLETED!\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Training time: {training_duration/60:.2f} minutes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc4d67e",
   "metadata": {},
   "source": [
    "## Save Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b9bec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "print(\"Saving trained model...\")\n",
    "\n",
    "os.makedirs(output_model_dir, exist_ok=True)\n",
    "trainer.save_model(output_model_dir)\n",
    "tokenizer.save_pretrained(output_model_dir)\n",
    "\n",
    "# Save label mappings\n",
    "with open(os.path.join(output_model_dir, 'label_mappings.json'), 'w') as f:\n",
    "    json.dump({'label2id': label2id, 'id2label': id2label}, f, indent=2)\n",
    "\n",
    "print(f\"Model saved to: {output_model_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ac7e8f",
   "metadata": {},
   "source": [
    "## Load Model for Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66781787",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the trained model for inference\n",
    "print(\"Loading trained model for inference...\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load tokenizer first (it has the correct vocabulary with special tokens)\n",
    "inference_tokenizer = AutoTokenizer.from_pretrained(output_model_dir)\n",
    "\n",
    "# Initialize model architecture\n",
    "inference_model = BertForREWithEntityMarkers(model_name, num_labels=len(RELATION_LABELS))\n",
    "\n",
    "# IMPORTANT: Resize embeddings BEFORE loading state dict to match saved model\n",
    "inference_model.bert.resize_token_embeddings(len(inference_tokenizer))\n",
    "\n",
    "# Try loading the model - handle both old and new formats\n",
    "try:\n",
    "    # Try new format first (model.safetensors or pytorch_model.bin in subfolder)\n",
    "    state_dict_path = os.path.join(output_model_dir, \"model.safetensors\")\n",
    "    if os.path.exists(state_dict_path):\n",
    "        from safetensors.torch import load_file\n",
    "        state_dict = load_file(state_dict_path)\n",
    "    else:\n",
    "        # Try old format\n",
    "        state_dict_path = os.path.join(output_model_dir, \"pytorch_model.bin\")\n",
    "        state_dict = torch.load(state_dict_path, map_location=device)\n",
    "    \n",
    "    inference_model.load_state_dict(state_dict)\n",
    "    print(f\"Loaded model from: {state_dict_path}\")\n",
    "except FileNotFoundError:\n",
    "    # If no checkpoint file, try loading the full model directly\n",
    "    # This happens when trainer saves the full model\n",
    "    print(\"Standard checkpoint not found, trying alternative loading method...\")\n",
    "    \n",
    "    # List files in the directory to debug\n",
    "    if os.path.exists(output_model_dir):\n",
    "        files = os.listdir(output_model_dir)\n",
    "        print(f\"Files in {output_model_dir}: {files}\")\n",
    "    \n",
    "    # Try to load from checkpoint subdirectory\n",
    "    checkpoint_dirs = [d for d in os.listdir(output_model_dir) if d.startswith('checkpoint-')]\n",
    "    if checkpoint_dirs:\n",
    "        # Use the last checkpoint\n",
    "        checkpoint_dirs.sort(key=lambda x: int(x.split('-')[1]))\n",
    "        checkpoint_path = os.path.join(output_model_dir, checkpoint_dirs[-1])\n",
    "        print(f\"Loading from checkpoint: {checkpoint_path}\")\n",
    "        \n",
    "        # Load from checkpoint\n",
    "        if os.path.exists(os.path.join(checkpoint_path, \"model.safetensors\")):\n",
    "            from safetensors.torch import load_file\n",
    "            state_dict = load_file(os.path.join(checkpoint_path, \"model.safetensors\"))\n",
    "        else:\n",
    "            state_dict = torch.load(os.path.join(checkpoint_path, \"pytorch_model.bin\"), map_location=device)\n",
    "        \n",
    "        inference_model.load_state_dict(state_dict)\n",
    "    else:\n",
    "        raise FileNotFoundError(f\"Could not find model checkpoint in {output_model_dir}\")\n",
    "\n",
    "inference_model.to(device)\n",
    "inference_model.eval()\n",
    "\n",
    "# Reload token IDs\n",
    "e1_token_id = inference_tokenizer.convert_tokens_to_ids(\"[E1]\")\n",
    "e2_token_id = inference_tokenizer.convert_tokens_to_ids(\"[E2]\")\n",
    "\n",
    "print(f\"Model loaded successfully\")\n",
    "print(f\"  Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc585e7",
   "metadata": {},
   "source": [
    "## Inference Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf9ad39",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_relation(model, tokenizer, text, subject, obj, e1_token_id, e2_token_id, id2label, device):\n",
    "    \"\"\"\n",
    "    Predict relation between two entities.\n",
    "    \n",
    "    Returns:\n",
    "        Predicted relation label and confidence score\n",
    "    \"\"\"\n",
    "    # Insert entity markers\n",
    "    marked_text = insert_entity_markers(text, subject, obj)\n",
    "    \n",
    "    # Tokenize\n",
    "    encoding = tokenizer(\n",
    "        marked_text,\n",
    "        truncation=True,\n",
    "        max_length=512,\n",
    "        padding='max_length',\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "    \n",
    "    input_ids = encoding['input_ids'].to(device)\n",
    "    attention_mask = encoding['attention_mask'].to(device)\n",
    "    \n",
    "    # Create entity masks\n",
    "    e1_mask = (input_ids == e1_token_id).long()\n",
    "    e2_mask = (input_ids == e2_token_id).long()\n",
    "    \n",
    "    # Predict\n",
    "    with torch.no_grad():\n",
    "        outputs = model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            e1_mask=e1_mask,\n",
    "            e2_mask=e2_mask\n",
    "        )\n",
    "        logits = outputs['logits']\n",
    "        probs = torch.softmax(logits, dim=-1)\n",
    "        \n",
    "        pred_label_id = torch.argmax(logits, dim=-1).item()\n",
    "        confidence = probs[0, pred_label_id].item()\n",
    "    \n",
    "    pred_label = id2label[pred_label_id]\n",
    "    \n",
    "    return pred_label, confidence\n",
    "\n",
    "\n",
    "print(\"Inference function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fda6bac5",
   "metadata": {},
   "source": [
    "## Predict on Dev Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "562d93b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run inference on dev set\n",
    "print(\"Running inference on dev set...\")\n",
    "\n",
    "predictions = {}\n",
    "\n",
    "for pmid, article in tqdm(dev_data.items(), desc=\"Predicting relations\"):\n",
    "    title = article['metadata']['title']\n",
    "    abstract = article['metadata']['abstract']\n",
    "    full_text, abstract_offset = create_full_text_with_offsets(title, abstract)\n",
    "    \n",
    "    entities = article['entities']\n",
    "    adjusted_entities = [adjust_entity_positions(e, abstract_offset) for e in entities]\n",
    "    \n",
    "    predicted_relations = []\n",
    "    \n",
    "    # Generate entity pairs - only for legal entity type combinations\n",
    "    for i, subject in enumerate(adjusted_entities):\n",
    "        for j, obj in enumerate(adjusted_entities):\n",
    "            if i != j:  # Don't create self-relations\n",
    "                # Check if this entity type pair is legal\n",
    "                type_pair = (subject['label'], obj['label'])\n",
    "                if type_pair not in legal_pairs:\n",
    "                    continue  # Skip non-legal entity type pairs\n",
    "                \n",
    "                # Predict relation\n",
    "                pred_label, confidence = predict_relation(\n",
    "                    inference_model,\n",
    "                    inference_tokenizer,\n",
    "                    full_text,\n",
    "                    subject,\n",
    "                    obj,\n",
    "                    e1_token_id,\n",
    "                    e2_token_id,\n",
    "                    id2label,\n",
    "                    device\n",
    "                )\n",
    "                \n",
    "                # Only keep positive relations (not \"no relation\")\n",
    "                if pred_label != \"no relation\":\n",
    "                    # Map back to original entity positions\n",
    "                    orig_subject = next(e for e in entities \n",
    "                                       if e['text_span'] == subject['text_span'] and \n",
    "                                          e['label'] == subject['label'])\n",
    "                    orig_obj = next(e for e in entities \n",
    "                                   if e['text_span'] == obj['text_span'] and \n",
    "                                      e['label'] == obj['label'])\n",
    "                    \n",
    "                    predicted_relations.append({\n",
    "                        \"subject_start_idx\": orig_subject['start_idx'],\n",
    "                        \"subject_end_idx\": orig_subject['end_idx'],\n",
    "                        \"subject_location\": orig_subject['location'],\n",
    "                        \"subject_text_span\": orig_subject['text_span'],\n",
    "                        \"subject_label\": orig_subject['label'],\n",
    "                        \"predicate\": pred_label,\n",
    "                        \"object_start_idx\": orig_obj['start_idx'],\n",
    "                        \"object_end_idx\": orig_obj['end_idx'],\n",
    "                        \"object_location\": orig_obj['location'],\n",
    "                        \"object_text_span\": orig_obj['text_span'],\n",
    "                        \"object_label\": orig_obj['label']\n",
    "                    })\n",
    "    \n",
    "\n",
    "    predictions[pmid] = {\"relations\": predicted_relations}\n",
    "\n",
    "total_relations = sum(len(p['relations']) for p in predictions.values())\n",
    "print(f\"\\nInference completed: {len(predictions)} documents\")\n",
    "print(f\"  Total relations predicted: {total_relations}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f20204e",
   "metadata": {},
   "source": [
    "## Save Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92b17e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save predictions to file\n",
    "output_path = \"predictions/bert_re_predictions.json\"\n",
    "\n",
    "os.makedirs(\"predictions\", exist_ok=True)\n",
    "\n",
    "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(predictions, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"Predictions saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61af28de",
   "metadata": {},
   "source": [
    "## Example Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013236d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show example predictions\n",
    "print(\"Example Predictions:\\n\")\n",
    "\n",
    "sample_pmids = list(dev_data.keys())[:5]\n",
    "\n",
    "for pmid in sample_pmids:\n",
    "    article = dev_data[pmid]\n",
    "    pred = predictions[pmid]\n",
    "    \n",
    "    print(f\"Document PMID: {pmid}\")\n",
    "    print(f\"Title: {article['metadata']['title'][:100]}...\")\n",
    "    print(f\"\\nNumber of entities: {len(article['entities'])}\")\n",
    "    print(f\"Number of gold relations: {len(article['relations'])}\")\n",
    "    print(f\"Number of predicted relations: {len(pred['relations'])}\")\n",
    "    \n",
    "    # Show first few predicted relations\n",
    "    print(\"\\nSample predicted relations:\")\n",
    "    for relation in pred['relations'][:5]:\n",
    "        print(f\"  ({relation['subject_text_span']} [{relation['subject_label']}]) \"\n",
    "              f\"--[{relation['predicate']}]--> \"\n",
    "              f\"({relation['object_text_span']} [{relation['object_label']}])\")\n",
    "    \n",
    "    print(\"-\" * 80)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c4b14e",
   "metadata": {},
   "source": [
    "## Analysis: Relation Distribution by Predicate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8026f811",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count relations by predicate in predictions\n",
    "pred_predicate_counts = Counter()\n",
    "for pmid, pred in predictions.items():\n",
    "    for relation in pred['relations']:\n",
    "        pred_predicate_counts[relation['predicate']] += 1\n",
    "\n",
    "# Count relations by predicate in gold standard\n",
    "gold_predicate_counts = Counter()\n",
    "for pmid, article in dev_data.items():\n",
    "    for relation in article['relations']:\n",
    "        gold_predicate_counts[relation['predicate']] += 1\n",
    "\n",
    "print(\"Relation Distribution by Predicate:\")\n",
    "print(\"=\"*60)\n",
    "print(f\"{'Predicate':<30} {'Gold':<10} {'Predicted':<10}\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "all_predicates = set(gold_predicate_counts.keys()) | set(pred_predicate_counts.keys())\n",
    "for predicate in sorted(all_predicates):\n",
    "    print(f\"{predicate:<30} {gold_predicate_counts[predicate]:<10} {pred_predicate_counts[predicate]:<10}\")\n",
    "\n",
    "print(\"-\"*60)\n",
    "print(f\"{'TOTAL':<30} {sum(gold_predicate_counts.values()):<10} {sum(pred_predicate_counts.values()):<10}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede7070c",
   "metadata": {},
   "source": [
    "## Processing to evaluation format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443240c6",
   "metadata": {},
   "source": [
    "Remove relations not defined in the annotation guidelines and complete conversion to evaluation format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec14e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "output_path = \"predictions/rebel_finetuned_predictions.json\"\n",
    "predictions = json.load(open(output_path, 'r', encoding='utf-8'))\n",
    "dev_data = json.load(open(\"../data/Annotations/Dev/json_format/dev.json\"))\n",
    "\n",
    "dump_dict = {}\n",
    "for pmid, content in predictions.items():\n",
    "    dump_dict[pmid] = {\n",
    "        'metadata': dev_data[pmid]['metadata'],\n",
    "        'entities': dev_data[pmid]['entities'],\n",
    "        'relations': content['relations']\n",
    "    }\n",
    "\n",
    "predictions = dump_dict\n",
    "dump_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8677788",
   "metadata": {},
   "outputs": [],
   "source": [
    "LEGAL_RELATIONS = [\n",
    "    (\"DDF\", \"affect\", \"DDF\"),\n",
    "    (\"microbiome\", \"is linked to\", \"DDF\"),\n",
    "    (\"DDF\", \"target\", \"human\"),\n",
    "    (\"drug\", \"change effect\", \"DDF\"),\n",
    "    (\"DDF\", \"is a\", \"DDF\"),\n",
    "    (\"microbiome\", \"located in\", \"human\"),\n",
    "    (\"chemical\", \"influence\", \"DDF\"),\n",
    "    (\"dietary supplement\", \"influence\", \"DDF\"),\n",
    "    (\"DDF\", \"target\", \"animal\"),\n",
    "    (\"chemical\", \"impact\", \"microbiome\"),\n",
    "    (\"anatomical location\", \"located in\", \"animal\"),\n",
    "    (\"microbiome\", \"located in\", \"animal\"),\n",
    "    (\"chemical\", \"located in\", \"anatomical location\"),\n",
    "    (\"bacteria\", \"part of\", \"microbiome\"),\n",
    "    (\"DDF\", \"strike\", \"anatomical location\"),\n",
    "    (\"drug\", \"administered\", \"animal\"),\n",
    "    (\"bacteria\", \"influence\", \"DDF\"),\n",
    "    (\"drug\", \"impact\", \"microbiome\"),\n",
    "    (\"DDF\", \"change abundance\", \"microbiome\"),\n",
    "    (\"microbiome\", \"located in\", \"anatomical location\"),\n",
    "    (\"microbiome\", \"used by\", \"biomedical technique\"),\n",
    "    (\"chemical\", \"produced by\", \"microbiome\"),\n",
    "    (\"dietary supplement\", \"impact\", \"microbiome\"),\n",
    "    (\"bacteria\", \"located in\", \"animal\"),\n",
    "    (\"animal\", \"used by\", \"biomedical technique\"),\n",
    "    (\"chemical\", \"impact\", \"bacteria\"),\n",
    "    (\"chemical\", \"located in\", \"animal\"),\n",
    "    (\"food\", \"impact\", \"bacteria\"),\n",
    "    (\"microbiome\", \"compared to\", \"microbiome\"),\n",
    "    (\"human\", \"used by\", \"biomedical technique\"),\n",
    "    (\"bacteria\", \"change expression\", \"gene\"),\n",
    "    (\"chemical\", \"located in\", \"human\"),\n",
    "    (\"drug\", \"interact\", \"chemical\"),\n",
    "    (\"food\", \"administered\", \"human\"),\n",
    "    (\"DDF\", \"change abundance\", \"bacteria\"),\n",
    "    (\"chemical\", \"interact\", \"chemical\"),\n",
    "    (\"chemical\", \"part of\", \"chemical\"),\n",
    "    (\"dietary supplement\", \"impact\", \"bacteria\"),\n",
    "    (\"DDF\", \"interact\", \"chemical\"),\n",
    "    (\"food\", \"impact\", \"microbiome\"),\n",
    "    (\"food\", \"influence\", \"DDF\"),\n",
    "    (\"bacteria\", \"located in\", \"human\"),\n",
    "    (\"dietary supplement\", \"administered\", \"human\"),\n",
    "    (\"bacteria\", \"interact\", \"chemical\"),\n",
    "    (\"drug\", \"change expression\", \"gene\"),\n",
    "    (\"drug\", \"impact\", \"bacteria\"),\n",
    "    (\"drug\", \"administered\", \"human\"),\n",
    "    (\"anatomical location\", \"located in\", \"human\"),\n",
    "    (\"dietary supplement\", \"change expression\", \"gene\"),\n",
    "    (\"chemical\", \"change expression\", \"gene\"),\n",
    "    (\"bacteria\", \"interact\", \"bacteria\"),\n",
    "    (\"drug\", \"interact\", \"drug\"),\n",
    "    (\"microbiome\", \"change expression\", \"gene\"),\n",
    "    (\"bacteria\", \"interact\", \"drug\"),\n",
    "    (\"food\", \"change expression\", \"gene\")\n",
    "]\n",
    "\n",
    "def remove_illegal_relations(data):\n",
    "    dump_dict = {}\n",
    "    total_rels = 0\n",
    "    kept_rels = 0\n",
    "    discared_rels = 0\n",
    "    discared_rels_set = set()\n",
    "\n",
    "    for pmid, article in data.items():\n",
    "        dump_dict[pmid] = {}\n",
    "        dump_dict[pmid]['metadata'] = article['metadata']\n",
    "        dump_dict[pmid]['entities'] = []\n",
    "        dump_dict[pmid]['relations'] = []\n",
    "\n",
    "        for entity in article['entities']:\n",
    "            dump_dict[pmid]['entities'].append({\n",
    "                \"start_idx\": entity[\"start_idx\"],\n",
    "                \"end_idx\": entity[\"end_idx\"],\n",
    "                \"location\": entity[\"location\"],\n",
    "                \"text_span\": entity[\"text_span\"],\n",
    "                \"label\": entity[\"label\"] if entity['label'] != 'DDF' else 'DDF'\n",
    "            })\n",
    "        \n",
    "        for relation in article['relations']:\n",
    "            total_rels += 1\n",
    "            rel_key = (relation[\"subject_label\"], relation[\"predicate\"], relation[\"object_label\"])\n",
    "            if rel_key in LEGAL_RELATIONS:\n",
    "                kept_rels += 1\n",
    "                dump_dict[pmid]['relations'].append({\n",
    "                    \"subject_start_idx\": relation[\"subject_start_idx\"],\n",
    "                    \"subject_end_idx\": relation[\"subject_end_idx\"],\n",
    "                    \"subject_location\": relation[\"subject_location\"],\n",
    "                    \"subject_text_span\": relation[\"subject_text_span\"],\n",
    "                    \"subject_label\": relation[\"subject_label\"] if relation[\"subject_label\"] != 'DDF' else 'DDF',\n",
    "                    \"predicate\": relation[\"predicate\"],\n",
    "                    \"object_start_idx\": relation[\"object_start_idx\"],\n",
    "                    \"object_end_idx\": relation[\"object_end_idx\"],\n",
    "                    \"object_location\": relation[\"object_location\"],\n",
    "                    \"object_text_span\": relation[\"object_text_span\"],\n",
    "                    \"object_label\": relation[\"object_label\"] if relation[\"object_label\"] != 'DDF' else 'DDF'\n",
    "                })\n",
    "            else:\n",
    "                discared_rels += 1\n",
    "                discared_rels_set.add(rel_key)\n",
    "\n",
    "    print(f'total_rels: {total_rels}')\n",
    "    print(f'kept_rels: {kept_rels}')\n",
    "    print(f'discared_rels: {discared_rels}')\n",
    "    print()\n",
    "    print(f'discared_rels_set: {discared_rels_set}')\n",
    "    for entry in discared_rels_set:\n",
    "        print(entry)\n",
    "\n",
    "    return dump_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec58b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "dump_dict = remove_illegal_relations(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24b3a5a2",
   "metadata": {},
   "source": [
    "Sort entities and relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f36231f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_entities(release_dict):\n",
    "\tdef get_sorting_key(entity):\n",
    "\t\tlocation_priority = 0 if entity[\"location\"] == \"title\" else 1\n",
    "\t\treturn (location_priority, entity[\"start_idx\"])\n",
    "\n",
    "\tfor pmid, article in release_dict.items():\n",
    "\t\tarticle[\"entities\"].sort(key=get_sorting_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cceeb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_entities(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "945e84f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_relations(release_dict):\n",
    "\tdef get_sorting_key(relation):\n",
    "\t\tlocation_priority = 0 if relation[\"subject_location\"] == \"title\" else 1\n",
    "\t\treturn (location_priority, relation[\"subject_start_idx\"])\n",
    "\n",
    "\tfor pmid, article in release_dict.items():\n",
    "\t\tarticle[\"relations\"].sort(key=get_sorting_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5dd4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sort_relations(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff5aa64c",
   "metadata": {},
   "source": [
    "Generate Binary Tag Based Relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad15904",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_binary_tag_based_relations_to_release_dict(release_dict):\n",
    "    for pmid, article in release_dict.items():\n",
    "        pairs = set()\n",
    "        for relation in article[\"relations\"]:\n",
    "            pairs.add((relation[\"subject_label\"], relation[\"object_label\"]))\n",
    "        if \"binary_tag_based_relations\" not in release_dict[pmid]:    \n",
    "            release_dict[pmid][\"binary_tag_based_relations\"] = []\n",
    "        for entry in pairs:\n",
    "            release_dict[pmid][\"binary_tag_based_relations\"].append({\"subject_label\": entry[0], \"object_label\": entry[1]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca0883ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_binary_tag_based_relations_to_release_dict(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d7f4c7",
   "metadata": {},
   "source": [
    "Generate Ternary Tag Based Relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad4c562",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_ternary_tag_based_relations_to_release_dict(release_dict):\n",
    "    for pmid, article in release_dict.items():\n",
    "        triplets = set()\n",
    "        for relation in article[\"relations\"]:\n",
    "            triplets.add((relation[\"subject_label\"], relation[\"predicate\"], relation[\"object_label\"]))\n",
    "        if \"ternary_tag_based_relations\" not in release_dict[pmid]:\n",
    "            release_dict[pmid][\"ternary_tag_based_relations\"] = []\n",
    "        for entry in triplets:\n",
    "            release_dict[pmid][\"ternary_tag_based_relations\"].append({\"subject_label\": entry[0], \"predicate\": entry[1], \"object_label\": entry[2]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded521d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "add_ternary_tag_based_relations_to_release_dict(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98644ab",
   "metadata": {},
   "source": [
    "Generate Ternary Mention Based Relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e81449c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_ternary_mention_based_relations_to_release_dict(release_dict):\n",
    "    for pmid, article in release_dict.items():\n",
    "        tuples = set()\n",
    "        for relation in article[\"relations\"]:\n",
    "            tuples.add((relation[\"subject_text_span\"], relation[\"subject_label\"], relation[\"predicate\"], relation[\"object_text_span\"], relation[\"object_label\"]))\n",
    "        if \"ternary_mention_based_relations\" not in release_dict[pmid]:\n",
    "            release_dict[pmid][\"ternary_mention_based_relations\"] = []\t\t\n",
    "        for entry in tuples:\n",
    "            release_dict[pmid][\"ternary_mention_based_relations\"].append({\"subject_text_span\": entry[0], \"subject_label\": entry[1], \"predicate\": entry[2], \"object_text_span\": entry[3], \"object_label\": entry[4]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6bf4c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "add_ternary_mention_based_relations_to_release_dict(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e8105c",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = output_path.replace(\".json\", \"_eval_format.json\")\n",
    "\n",
    "with open(output_path, 'w', encoding='utf-8') as file:\n",
    "    json.dump(predictions, file, indent=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ate-it",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
