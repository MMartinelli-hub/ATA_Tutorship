{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da4b39ee",
   "metadata": {},
   "source": [
    "# BERT-Based Term Clustering\n",
    "\n",
    "This notebook demonstrates BERT-based approaches to term clustering:\n",
    "1. **Baseline**: Similarity-based clustering using BERT embeddings\n",
    "2. **Advanced**: K-means clustering with BERT contextual embeddings\n",
    "\n",
    "Uses Italian BERT model to generate contextualized term representations.\n",
    "\n",
    "Dataset: EvalITA 2025 ATE-IT (Automatic Term Extraction - Italian Testbed) - Subtask B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5a02b42",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7e41243",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\marti\\miniconda3\\envs\\ate-it\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete\n",
      "PyTorch version: 2.9.0+cpu\n",
      "CUDA available: False\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score, normalized_mutual_info_score, v_measure_score\n",
    "from sklearn.metrics import homogeneity_score, completeness_score\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set random seeds\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"Setup complete\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1b8a5a",
   "metadata": {},
   "source": [
    "## Load BERT Model\n",
    "\n",
    "Using Italian BERT for contextual embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3fd8b6a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model: dbmdz/bert-base-italian-uncased\n",
      "Model loaded: BertModel\n",
      "Device: cpu\n",
      "Tokenizer vocab size: 31102\n",
      "Model loaded: BertModel\n",
      "Device: cpu\n",
      "Tokenizer vocab size: 31102\n"
     ]
    }
   ],
   "source": [
    "# Load Italian BERT model\n",
    "model_name = \"dbmdz/bert-base-italian-uncased\"\n",
    "\n",
    "print(f\"Loading model: {model_name}\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "bert_model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "# Set to evaluation mode\n",
    "bert_model.eval()\n",
    "\n",
    "# Move to GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "bert_model = bert_model.to(device)\n",
    "\n",
    "print(f\"Model loaded: {bert_model.__class__.__name__}\")\n",
    "print(f\"Device: {device}\")\n",
    "print(f\"Tokenizer vocab size: {tokenizer.vocab_size}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a77f6b",
   "metadata": {},
   "source": [
    "## Load Training and Dev Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "560cd1f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (713, 2)\n",
      "Number of unique clusters: 299\n",
      "Number of terms: 713\n",
      "\n",
      "Dev data shape: (242, 2)\n",
      "Number of unique clusters in dev: 147\n",
      "Number of terms in dev: 242\n",
      "\n",
      "Example clusters from training:\n",
      "  Cluster 0: ['biodegradabili']\n",
      "  Cluster 1: ['cassonetti', 'contenitori stradali', 'cassonetti stradali', 'postazioni stradali']\n",
      "  Cluster 2: ['separare i rifiuti']\n",
      "  Cluster 3: ['deposito', 'conferimento', 'conferimento delle frazioni', 'conferimento dei rifiuti', 'conferimenti', 'operazioni di conferimento']\n",
      "  Cluster 4: ['conferiti', 'conferito', 'conferita']\n"
     ]
    }
   ],
   "source": [
    "data_path = \"../data\"\n",
    "train_path = os.path.join(data_path, \"subtask_b_train.csv\")\n",
    "dev_path = os.path.join(data_path, \"subtask_b_dev.csv\")\n",
    "\n",
    "# Load training data\n",
    "train_df = pd.read_csv(train_path)\n",
    "print(f\"Training data shape: {train_df.shape}\")\n",
    "print(f\"Number of unique clusters: {train_df['cluster'].nunique()}\")\n",
    "print(f\"Number of terms: {len(train_df)}\")\n",
    "\n",
    "# Load dev data\n",
    "dev_df = pd.read_csv(dev_path)\n",
    "print(f\"\\nDev data shape: {dev_df.shape}\")\n",
    "print(f\"Number of unique clusters in dev: {dev_df['cluster'].nunique()}\")\n",
    "print(f\"Number of terms in dev: {len(dev_df)}\")\n",
    "\n",
    "# Create term-to-cluster mapping\n",
    "term_to_cluster = dict(zip(train_df['term'].str.lower(), train_df['cluster']))\n",
    "\n",
    "# Create cluster-to-terms mapping for analysis\n",
    "cluster_to_terms = defaultdict(list)\n",
    "for term, cluster in term_to_cluster.items():\n",
    "    cluster_to_terms[cluster].append(term)\n",
    "\n",
    "print(f\"\\nExample clusters from training:\")\n",
    "for cluster_id in sorted(cluster_to_terms.keys())[:5]:\n",
    "    print(f\"  Cluster {cluster_id}: {cluster_to_terms[cluster_id]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033e4061",
   "metadata": {},
   "source": [
    "## BERT Embedding Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26c19e13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " BERT embedding functions work!!\n",
      "  Test text: 'raccolta differenziata'\n",
      "  Embedding shape: (768,)\n",
      "  Embedding sample: [ 0.12397581  0.08731506  0.41113496  0.20128354 -0.12553388]\n"
     ]
    }
   ],
   "source": [
    "def get_bert_embedding(text: str, model, tokenizer, device) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Get BERT embedding for a text.\n",
    "    Returns the [CLS] token representation from the last hidden layer.\n",
    "    \"\"\"\n",
    "    # Tokenize\n",
    "    inputs = tokenizer(\n",
    "        text,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=128\n",
    "    )\n",
    "    \n",
    "    # Move to device\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    \n",
    "    # Get embeddings\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        # Use [CLS] token embedding from last hidden state\n",
    "        cls_embedding = outputs.last_hidden_state[:, 0, :].cpu().numpy()\n",
    "    \n",
    "    return cls_embedding[0]\n",
    "\n",
    "\n",
    "def get_bert_mean_pooling(text: str, model, tokenizer, device) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Get BERT embedding using mean pooling over all tokens.\n",
    "    \"\"\"\n",
    "    inputs = tokenizer(\n",
    "        text,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=128\n",
    "    )\n",
    "    \n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        # Mean pooling over all tokens\n",
    "        token_embeddings = outputs.last_hidden_state\n",
    "        attention_mask = inputs['attention_mask']\n",
    "        \n",
    "        # Apply attention mask for mean pooling\n",
    "        mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "        sum_embeddings = torch.sum(token_embeddings * mask_expanded, 1)\n",
    "        sum_mask = torch.clamp(mask_expanded.sum(1), min=1e-9)\n",
    "        mean_pooled = (sum_embeddings / sum_mask).cpu().numpy()\n",
    "    \n",
    "    return mean_pooled[0]\n",
    "\n",
    "\n",
    "# Test embedding functions\n",
    "test_text = \"raccolta differenziata\"\n",
    "test_embedding = get_bert_embedding(test_text, bert_model, tokenizer, device)\n",
    "print(f\" BERT embedding functions work!!\")\n",
    "print(f\"  Test text: '{test_text}'\")\n",
    "print(f\"  Embedding shape: {test_embedding.shape}\")\n",
    "print(f\"  Embedding sample: {test_embedding[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d133d5c",
   "metadata": {},
   "source": [
    "## Baseline: BERT Similarity-Based Clustering\n",
    "\n",
    "For each dev term, find the most similar training term using BERT embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23fca26c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing BERT embeddings for training terms...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 18.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built index with 3 terms\n",
      "\n",
      " Baseline model works!!\n",
      "  'spazzatura' -> Cluster 37 (similarity: 0.956)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "class BERTBaselineClustering:\n",
    "    \"\"\"Similarity-based clustering using BERT embeddings.\"\"\"\n",
    "    \n",
    "    def __init__(self, bert_model, tokenizer, device, similarity_threshold=0.7, use_mean_pooling=False):\n",
    "        self.bert_model = bert_model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.device = device\n",
    "        self.similarity_threshold = similarity_threshold\n",
    "        self.use_mean_pooling = use_mean_pooling\n",
    "        self.term_embeddings = {}\n",
    "        self.term_to_cluster = {}\n",
    "    \n",
    "    def _get_embedding(self, text: str) -> np.ndarray:\n",
    "        \"\"\"Get BERT embedding for text.\"\"\"\n",
    "        if self.use_mean_pooling:\n",
    "            return get_bert_mean_pooling(text, self.bert_model, self.tokenizer, self.device)\n",
    "        else:\n",
    "            return get_bert_embedding(text, self.bert_model, self.tokenizer, self.device)\n",
    "    \n",
    "    def fit(self, terms: List[str], clusters: List[int]):\n",
    "        \"\"\"Precompute embeddings for training terms.\"\"\"\n",
    "        print(\"Computing BERT embeddings for training terms...\")\n",
    "        for term, cluster in tqdm(zip(terms, clusters), total=len(terms)):\n",
    "            term_lower = term.lower()\n",
    "            self.term_to_cluster[term_lower] = cluster\n",
    "            self.term_embeddings[term_lower] = self._get_embedding(term_lower)\n",
    "        \n",
    "        print(f\"Built index with {len(self.term_embeddings)} terms\")\n",
    "    \n",
    "    def predict_one(self, term: str) -> Tuple[int, float]:\n",
    "        \"\"\"Predict cluster for a single term.\"\"\"\n",
    "        term_lower = term.lower()\n",
    "        \n",
    "        # Check for exact match\n",
    "        if term_lower in self.term_to_cluster:\n",
    "            return self.term_to_cluster[term_lower], 1.0\n",
    "        \n",
    "        # Get embedding for query term\n",
    "        query_embedding = self._get_embedding(term_lower).reshape(1, -1)\n",
    "        \n",
    "        # Compute similarities with all training terms\n",
    "        best_similarity = 0.0\n",
    "        best_cluster = -1\n",
    "        \n",
    "        for train_term, train_embedding in self.term_embeddings.items():\n",
    "            train_emb_reshaped = train_embedding.reshape(1, -1)\n",
    "            sim = cosine_similarity(query_embedding, train_emb_reshaped)[0, 0]\n",
    "            \n",
    "            if sim > best_similarity:\n",
    "                best_similarity = sim\n",
    "                best_cluster = self.term_to_cluster[train_term]\n",
    "        \n",
    "        # Check threshold\n",
    "        if best_similarity < self.similarity_threshold:\n",
    "            return -1, best_similarity\n",
    "        \n",
    "        return best_cluster, best_similarity\n",
    "    \n",
    "    def predict(self, terms: List[str]) -> Tuple[List[int], List[float]]:\n",
    "        \"\"\"Predict clusters for multiple terms.\"\"\"\n",
    "        predictions = []\n",
    "        similarities = []\n",
    "        \n",
    "        for term in tqdm(terms, desc=\"Predicting clusters\"):\n",
    "            cluster, sim = self.predict_one(term)\n",
    "            predictions.append(cluster)\n",
    "            similarities.append(sim)\n",
    "        \n",
    "        return predictions, similarities\n",
    "    \n",
    "    def save(self, path: str):\n",
    "        \"\"\"Save model to disk.\"\"\"\n",
    "        os.makedirs(os.path.dirname(path) or '.', exist_ok=True)\n",
    "        model_data = {\n",
    "            'similarity_threshold': self.similarity_threshold,\n",
    "            'use_mean_pooling': self.use_mean_pooling,\n",
    "            'term_embeddings': self.term_embeddings,\n",
    "            'term_to_cluster': self.term_to_cluster\n",
    "        }\n",
    "        with open(path, 'wb') as f:\n",
    "            pickle.dump(model_data, f)\n",
    "        print(f\"Model saved to {path}\")\n",
    "    \n",
    "    def load(self, path: str):\n",
    "        \"\"\"Load model from disk.\"\"\"\n",
    "        with open(path, 'rb') as f:\n",
    "            model_data = pickle.load(f)\n",
    "        self.similarity_threshold = model_data['similarity_threshold']\n",
    "        self.use_mean_pooling = model_data['use_mean_pooling']\n",
    "        self.term_embeddings = model_data['term_embeddings']\n",
    "        self.term_to_cluster = model_data['term_to_cluster']\n",
    "        print(f\"Model loaded from {path}\")\n",
    "\n",
    "\n",
    "# Test\n",
    "test_model = BERTBaselineClustering(bert_model, tokenizer, device, similarity_threshold=0.7)\n",
    "test_terms_list = ['rifiuti', 'carta', 'plastica']\n",
    "test_clusters_list = [37, 74, 43]\n",
    "test_model.fit(test_terms_list, test_clusters_list)\n",
    "pred_cluster, pred_sim = test_model.predict_one('spazzatura')\n",
    "print(f\"\\n Baseline model works!!\")\n",
    "print(f\"  'spazzatura' -> Cluster {pred_cluster} (similarity: {pred_sim:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4561153",
   "metadata": {},
   "source": [
    "### Train and Evaluate Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85c8a780",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing BERT embeddings for training terms...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 713/713 [00:15<00:00, 47.07it/s]\n",
      "100%|██████████| 713/713 [00:15<00:00, 47.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built index with 713 terms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting clusters: 100%|██████████| 242/242 [00:12<00:00, 18.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction statistics:\n",
      "  Total terms: 242\n",
      "  Terms with exact match: 140\n",
      "  Terms with high similarity (≥0.85): 100\n",
      "  Terms with medium similarity (0.7-0.85): 2\n",
      "  Terms below threshold (unknown): 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize baseline model\n",
    "baseline_model = BERTBaselineClustering(\n",
    "    bert_model, \n",
    "    tokenizer, \n",
    "    device, \n",
    "    similarity_threshold=0.7,\n",
    "    use_mean_pooling=False  # Use CLS token\n",
    ")\n",
    "\n",
    "# Fit on training data\n",
    "baseline_model.fit(train_df['term'].tolist(), train_df['cluster'].tolist())\n",
    "\n",
    "# Predict on dev set\n",
    "baseline_preds, baseline_sims = baseline_model.predict(dev_df['term'].tolist())\n",
    "\n",
    "# Store results\n",
    "dev_df['baseline_cluster'] = baseline_preds\n",
    "dev_df['baseline_similarity'] = baseline_sims\n",
    "\n",
    "print(f\"\\nPrediction statistics:\")\n",
    "print(f\"  Total terms: {len(baseline_preds)}\")\n",
    "print(f\"  Terms with exact match: {sum(1 for s in baseline_sims if s >= 0.99)}\")\n",
    "print(f\"  Terms with high similarity (≥0.85): {sum(1 for s in baseline_sims if 0.85 <= s < 0.99)}\")\n",
    "print(f\"  Terms with medium similarity (0.7-0.85): {sum(1 for s in baseline_sims if 0.7 <= s < 0.85)}\")\n",
    "print(f\"  Terms below threshold (unknown): {sum(1 for p in baseline_preds if p == -1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aed7b8d",
   "metadata": {},
   "source": [
    "## Save Models and Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1da4bd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to models/bert_clustering_baseline.pkl\n",
      "Model saved to models/bert_clustering_kmeans.pkl\n",
      "\n",
      "Baseline predictions saved to predictions/subtask_b_dev_bert_baseline_preds.csv\n",
      "K-means predictions saved to predictions/subtask_b_dev_bert_kmeans_preds.csv\n"
     ]
    }
   ],
   "source": [
    "# Save baseline model\n",
    "baseline_model.save('models/bert_clustering_baseline.pkl')\n",
    "\n",
    "# Save predictions\n",
    "output_path_baseline = \"predictions/subtask_b_dev_bert_baseline_preds.csv\"\n",
    "#dev_df[['term', 'baseline_cluster', 'baseline_similarity']].to_csv(output_path_baseline, index=False)\n",
    "dev_df[['term', 'baseline_cluster']].to_csv(output_path_baseline, index=False)\n",
    "print(f\"\\nBaseline predictions saved to {output_path_baseline}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d01446a",
   "metadata": {},
   "source": [
    "### Evaluate Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d16e8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import codecs\n",
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "def load_data(file_path):\n",
    "  \"\"\"\n",
    "  Loads data from a CSV or JSON file and returns a dictionary\n",
    "  where keys are terms and values are cluster_ids.\n",
    "\n",
    "  Args:\n",
    "    file_path: The path to the input file (CSV or JSON).\n",
    "\n",
    "  Returns:\n",
    "    A dictionary containing the loaded data.\n",
    "\n",
    "  Raises:\n",
    "    ValueError: If the file format is not supported.\n",
    "  \"\"\"\n",
    "  if file_path.endswith('.csv'):\n",
    "    # Load data from CSV file\n",
    "    df = pd.read_csv(file_path)\n",
    "    data = {term: int(cluster) for term, cluster in df.itertuples(index=False)}\n",
    "  elif file_path.endswith('.json'):\n",
    "    # Load data from JSON file\n",
    "    with codecs.open(file_path, 'r', 'utf-8') as f:\n",
    "      json_data = json.load(f)\n",
    "    # Extract terms from JSON data\n",
    "    data = {item[\"term\"]: item[\"cluster\"] for item in json_data[\"data\"]}\n",
    "  else:\n",
    "    # Raise error for unsupported file formats\n",
    "    raise ValueError(\"Unsupported file format. Only CSV and JSON files are supported.\")\n",
    "  return data\n",
    "\n",
    "class BCubed_calculator:\n",
    "  def __init__(self, gold, pred):\n",
    "    self.gold = gold\n",
    "    self.pred = pred\n",
    "    self.gold_cluster = defaultdict(set)\n",
    "    self.pred_cluster = defaultdict(set)\n",
    "    for item, clus_id in gold.items():\n",
    "        self.gold_cluster[clus_id].add(item)\n",
    "    for item, clus_id in pred.items():\n",
    "      self.pred_cluster[clus_id].add(item)\n",
    "\n",
    "  def bc_precision_item(self, item):\n",
    "    pred_id = self.pred[item]\n",
    "    gold_id = self.gold.get(item, None)\n",
    "    TP = len(self.pred_cluster[pred_id].intersection(self.gold_cluster[gold_id]))\n",
    "    FP = len(self.pred_cluster[pred_id]) - TP\n",
    "    return TP/(FP + TP)\n",
    "\n",
    "  def bc_recall_item(self, item):\n",
    "    pred_id = self.pred.get(item, None)\n",
    "    gold_id = self.gold.get(item)\n",
    "    TP = len(self.pred_cluster[pred_id].intersection(self.gold_cluster[gold_id]))\n",
    "    FN = len(self.gold_cluster[gold_id]) - TP\n",
    "    return TP/(TP + FN)\n",
    "\n",
    "def bcubed_precision(gold, pred):\n",
    "  calc = BCubed_calculator(gold, pred)\n",
    "  return np.average([calc.bc_precision_item(item) for item in calc.pred])\n",
    "\n",
    "def bcubed_recall(gold, pred):\n",
    "  calc = BCubed_calculator(gold, pred)\n",
    "  return np.average([calc.bc_recall_item(item) for item in calc.gold])\n",
    "\n",
    "def bcubed_f1(gold, pred):\n",
    "  return 2 * bcubed_precision(gold, pred) * bcubed_recall(gold, pred) / (bcubed_precision(gold, pred) + bcubed_recall(gold, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "709850b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BCubed Precision: 0.7428\n",
      "BCubed Recall: 0.8621\n",
      "BCubed F1: 0.7980\n"
     ]
    }
   ],
   "source": [
    "preds = load_data(\"predictions/subtask_b_dev_bert_baseline_preds.csv\")\n",
    "gold = load_data(\"../data/subtask_b_dev.csv\")\n",
    "print(f\"BCubed Precision: {bcubed_precision(gold, preds):.4f}\")\n",
    "print(f\"BCubed Recall: {bcubed_recall(gold, preds):.4f}\")\n",
    "print(f\"BCubed F1: {bcubed_f1(gold, preds):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa5bde2",
   "metadata": {},
   "source": [
    "## K-Means with BERT Embeddings\n",
    "\n",
    "Train K-means clustering on BERT embeddings of training terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a7a988b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing BERT embeddings for training terms...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 32.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings shape: (3, 768)\n",
      "Training K-means with 3 clusters...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete! Built mapping for 3 clusters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting clusters: 100%|██████████| 1/1 [00:00<00:00, 41.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " K-means model works!!\n",
      "  'spazzatura' -> Cluster 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "class BERTKMeansClustering:\n",
    "    \"\"\"K-means clustering using BERT embeddings.\"\"\"\n",
    "    \n",
    "    def __init__(self, bert_model, tokenizer, device, n_clusters=None, use_mean_pooling=False):\n",
    "        self.bert_model = bert_model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.device = device\n",
    "        self.n_clusters = n_clusters\n",
    "        self.use_mean_pooling = use_mean_pooling\n",
    "        self.kmeans = None\n",
    "        self.cluster_mapping = {}  # Maps learned cluster IDs to gold cluster IDs\n",
    "    \n",
    "    def _get_embedding(self, text: str) -> np.ndarray:\n",
    "        \"\"\"Get BERT embedding for text.\"\"\"\n",
    "        if self.use_mean_pooling:\n",
    "            return get_bert_mean_pooling(text, self.bert_model, self.tokenizer, self.device)\n",
    "        else:\n",
    "            return get_bert_embedding(text, self.bert_model, self.tokenizer, self.device)\n",
    "    \n",
    "    def fit(self, terms: List[str], true_clusters: List[int]):\n",
    "        \"\"\"Train K-means on BERT embeddings.\"\"\"\n",
    "        print(\"Computing BERT embeddings for training terms...\")\n",
    "        embeddings = []\n",
    "        \n",
    "        for term in tqdm(terms):\n",
    "            emb = self._get_embedding(term.lower())\n",
    "            embeddings.append(emb)\n",
    "        \n",
    "        embeddings = np.array(embeddings, dtype=np.float64)\n",
    "        print(f\"Embeddings shape: {embeddings.shape}\")\n",
    "        \n",
    "        # Determine number of clusters\n",
    "        if self.n_clusters is None:\n",
    "            self.n_clusters = len(set(true_clusters))\n",
    "        \n",
    "        print(f\"Training K-means with {self.n_clusters} clusters...\")\n",
    "        self.kmeans = KMeans(n_clusters=self.n_clusters, random_state=42, n_init=10)\n",
    "        learned_clusters = self.kmeans.fit_predict(embeddings)\n",
    "        \n",
    "        # Map learned cluster IDs to gold cluster IDs\n",
    "        self.cluster_mapping = {}\n",
    "        for learned_id in range(self.n_clusters):\n",
    "            mask = learned_clusters == learned_id\n",
    "            if sum(mask) > 0:\n",
    "                gold_clusters_in_learned = [true_clusters[i] for i, m in enumerate(mask) if m]\n",
    "                # Most common gold cluster in this learned cluster\n",
    "                most_common = max(set(gold_clusters_in_learned), key=gold_clusters_in_learned.count)\n",
    "                self.cluster_mapping[learned_id] = most_common\n",
    "        \n",
    "        print(f\"Training complete! Built mapping for {len(self.cluster_mapping)} clusters\")\n",
    "    \n",
    "    def predict(self, terms: List[str]) -> List[int]:\n",
    "        \"\"\"Predict clusters for new terms.\"\"\"\n",
    "        if self.kmeans is None:\n",
    "            raise RuntimeError(\"Model not trained. Call fit() first.\")\n",
    "        \n",
    "        predictions = []\n",
    "        \n",
    "        for term in tqdm(terms, desc=\"Predicting clusters\"):\n",
    "            emb = self._get_embedding(term.lower())\n",
    "            emb = np.array([emb], dtype=np.float64)\n",
    "            learned_cluster = self.kmeans.predict(emb)[0]\n",
    "            # Map to gold cluster ID\n",
    "            gold_cluster = self.cluster_mapping.get(learned_cluster, -1)\n",
    "            predictions.append(gold_cluster)\n",
    "        \n",
    "        return predictions\n",
    "    \n",
    "    def save(self, path: str):\n",
    "        \"\"\"Save model to disk.\"\"\"\n",
    "        os.makedirs(os.path.dirname(path) or '.', exist_ok=True)\n",
    "        model_data = {\n",
    "            'n_clusters': self.n_clusters,\n",
    "            'use_mean_pooling': self.use_mean_pooling,\n",
    "            'kmeans': self.kmeans,\n",
    "            'cluster_mapping': self.cluster_mapping\n",
    "        }\n",
    "        with open(path, 'wb') as f:\n",
    "            pickle.dump(model_data, f)\n",
    "        print(f\"Model saved to {path}\")\n",
    "    \n",
    "    def load(self, path: str):\n",
    "        \"\"\"Load model from disk.\"\"\"\n",
    "        with open(path, 'rb') as f:\n",
    "            model_data = pickle.load(f)\n",
    "        self.n_clusters = model_data['n_clusters']\n",
    "        self.use_mean_pooling = model_data['use_mean_pooling']\n",
    "        self.kmeans = model_data['kmeans']\n",
    "        self.cluster_mapping = model_data['cluster_mapping']\n",
    "        print(f\"Model loaded from {path}\")\n",
    "\n",
    "\n",
    "# Test\n",
    "test_kmeans = BERTKMeansClustering(bert_model, tokenizer, device)\n",
    "test_kmeans.fit(['rifiuti', 'carta', 'plastica'], [37, 74, 43])\n",
    "test_pred = test_kmeans.predict(['spazzatura'])\n",
    "print(f\"\\n K-means model works!!\")\n",
    "print(f\"  'spazzatura' -> Cluster {test_pred[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce6b5ce",
   "metadata": {},
   "source": [
    "### Train and Evaluate K-Means Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b37e5a64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing BERT embeddings for training terms...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 713/713 [00:14<00:00, 48.95it/s]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings shape: (713, 768)\n",
      "Training K-means with 299 clusters...\n",
      "Training complete! Built mapping for 299 clusters\n",
      "Training complete! Built mapping for 299 clusters\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting clusters: 100%|██████████| 242/242 [00:04<00:00, 50.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction statistics:\n",
      "  Total terms: 242\n",
      "  Terms with predictions: 242\n",
      "  Terms without predictions (unknown): 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize K-means model\n",
    "kmeans_model = BERTKMeansClustering(\n",
    "    bert_model, \n",
    "    tokenizer, \n",
    "    device,\n",
    "    use_mean_pooling=False\n",
    ")\n",
    "\n",
    "# Fit on training data\n",
    "kmeans_model.fit(train_df['term'].tolist(), train_df['cluster'].tolist())\n",
    "\n",
    "# Predict on dev set\n",
    "kmeans_preds = kmeans_model.predict(dev_df['term'].tolist())\n",
    "\n",
    "# Store results\n",
    "dev_df['kmeans_cluster'] = kmeans_preds\n",
    "\n",
    "print(f\"\\nPrediction statistics:\")\n",
    "print(f\"  Total terms: {len(kmeans_preds)}\")\n",
    "print(f\"  Terms with predictions: {sum(1 for p in kmeans_preds if p != -1)}\")\n",
    "print(f\"  Terms without predictions (unknown): {sum(1 for p in kmeans_preds if p == -1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7296919a",
   "metadata": {},
   "source": [
    "## Save Models and Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a73c4c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to models/bert_clustering_kmeans.pkl\n",
      "K-means predictions saved to predictions/subtask_b_dev_bert_kmeans_preds.csv\n"
     ]
    }
   ],
   "source": [
    "# Save K-means model\n",
    "kmeans_model.save('models/bert_clustering_kmeans.pkl')\n",
    "\n",
    "# Save predictions\n",
    "output_path_kmeans = \"predictions/subtask_b_dev_bert_kmeans_preds.csv\"\n",
    "dev_df[['term', 'kmeans_cluster']].to_csv(output_path_kmeans, index=False)\n",
    "print(f\"K-means predictions saved to {output_path_kmeans}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4b40e6",
   "metadata": {},
   "source": [
    "### Evaluate K-Means Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fd319046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BCubed Precision: 0.5389\n",
      "BCubed Recall: 0.7742\n",
      "BCubed F1: 0.6355\n"
     ]
    }
   ],
   "source": [
    "preds = load_data(\"predictions/subtask_b_dev_bert_kmeans_preds.csv\")\n",
    "gold = load_data(\"../data/subtask_b_dev.csv\")\n",
    "print(f\"BCubed Precision: {bcubed_precision(gold, preds):.4f}\")\n",
    "print(f\"BCubed Recall: {bcubed_recall(gold, preds):.4f}\")\n",
    "print(f\"BCubed F1: {bcubed_f1(gold, preds):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b0f9ba8",
   "metadata": {},
   "source": [
    "## Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c59d1587",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "MODEL COMPARISON - BCubed Metrics\n",
      "================================================================================\n",
      "                Model  BCubed Precision  BCubed Recall  BCubed F1\n",
      "Baseline (Similarity)          0.742788       0.862082   0.798001\n",
      "              K-Means          0.538905       0.774183   0.635466\n",
      "================================================================================\n",
      "\n",
      "K-Means vs Baseline:\n",
      "  BCubed Precision improvement: -27.4%\n",
      "  BCubed Recall improvement: -10.2%\n",
      "  BCubed F1 improvement: -20.4%\n"
     ]
    }
   ],
   "source": [
    "# Load predictions and gold standard for both models\n",
    "gold = load_data(\"../data/subtask_b_dev.csv\")\n",
    "baseline_preds = load_data(\"predictions/subtask_b_dev_bert_baseline_preds.csv\")\n",
    "kmeans_preds = load_data(\"predictions/subtask_b_dev_bert_kmeans_preds.csv\")\n",
    "\n",
    "# Compute BCubed metrics for baseline model\n",
    "baseline_precision = bcubed_precision(gold, baseline_preds)\n",
    "baseline_recall = bcubed_recall(gold, baseline_preds)\n",
    "baseline_f1 = bcubed_f1(gold, baseline_preds)\n",
    "\n",
    "# Compute BCubed metrics for K-means model\n",
    "kmeans_precision = bcubed_precision(gold, kmeans_preds)\n",
    "kmeans_recall = bcubed_recall(gold, kmeans_preds)\n",
    "kmeans_f1 = bcubed_f1(gold, kmeans_preds)\n",
    "\n",
    "# Create comparison dataframe\n",
    "comparison_df = pd.DataFrame([\n",
    "    {\n",
    "        'Model': 'Baseline (Similarity)',\n",
    "        'BCubed Precision': baseline_precision,\n",
    "        'BCubed Recall': baseline_recall,\n",
    "        'BCubed F1': baseline_f1\n",
    "    },\n",
    "    {\n",
    "        'Model': 'K-Means',\n",
    "        'BCubed Precision': kmeans_precision,\n",
    "        'BCubed Recall': kmeans_recall,\n",
    "        'BCubed F1': kmeans_f1\n",
    "    }\n",
    "])\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MODEL COMPARISON - BCubed Metrics\")\n",
    "print(\"=\"*80)\n",
    "print(comparison_df.to_string(index=False))\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Calculate improvements\n",
    "precision_improvement = (kmeans_precision - baseline_precision) / baseline_precision * 100 if baseline_precision > 0 else 0\n",
    "recall_improvement = (kmeans_recall - baseline_recall) / baseline_recall * 100 if baseline_recall > 0 else 0\n",
    "f1_improvement = (kmeans_f1 - baseline_f1) / baseline_f1 * 100 if baseline_f1 > 0 else 0\n",
    "\n",
    "print(f\"\\nK-Means vs Baseline:\")\n",
    "print(f\"  BCubed Precision improvement: {precision_improvement:+.1f}%\")\n",
    "print(f\"  BCubed Recall improvement: {recall_improvement:+.1f}%\")\n",
    "print(f\"  BCubed F1 improvement: {f1_improvement:+.1f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ate-it",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
