{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6e76559",
   "metadata": {},
   "source": [
    "# NLTK Term Clustering\n",
    "\n",
    "This notebook demonstrates two approaches to term clustering using NLTK:\n",
    "1. **Baseline**: String similarity and fuzzy matching\n",
    "2. **Trained**: TF-IDF based similarity clustering\n",
    "\n",
    "Dataset: EvalITA 2025 ATE-IT (Automatic Term Extraction - Italian Testbed) - Subtask B"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8380c217",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "73e2c34c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setup complete\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "import math\n",
    "import difflib\n",
    "import re\n",
    "from collections import Counter, defaultdict\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from sklearn.metrics import adjusted_rand_score, normalized_mutual_info_score, v_measure_score\n",
    "from sklearn.metrics import homogeneity_score, completeness_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Download required NLTK data\n",
    "nltk.download('punkt', quiet=True)\n",
    "print(\"Setup complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b1a452",
   "metadata": {},
   "source": [
    "## Load Training and Dev Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3cc97a39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (713, 2)\n",
      "Number of unique clusters: 299\n",
      "Number of terms: 713\n",
      "\n",
      "Dev data shape: (242, 2)\n",
      "Number of unique clusters in dev: 147\n",
      "Number of terms in dev: 242\n",
      "\n",
      "Example clusters from training:\n",
      "  Cluster 0: ['biodegradabili']\n",
      "  Cluster 1: ['cassonetti', 'contenitori stradali', 'cassonetti stradali', 'postazioni stradali']\n",
      "  Cluster 2: ['separare i rifiuti']\n",
      "  Cluster 3: ['deposito', 'conferimento', 'conferimento delle frazioni', 'conferimento dei rifiuti', 'conferimenti', 'operazioni di conferimento']\n",
      "  Cluster 4: ['conferiti', 'conferito', 'conferita']\n"
     ]
    }
   ],
   "source": [
    "data_path = \"../data\"\n",
    "train_path = os.path.join(data_path, \"subtask_b_train.csv\")\n",
    "dev_path = os.path.join(data_path, \"subtask_b_dev.csv\")\n",
    "\n",
    "# Load training data\n",
    "train_df = pd.read_csv(train_path)\n",
    "print(f\"Training data shape: {train_df.shape}\")\n",
    "print(f\"Number of unique clusters: {train_df['cluster'].nunique()}\")\n",
    "print(f\"Number of terms: {len(train_df)}\")\n",
    "\n",
    "# Load dev data\n",
    "dev_df = pd.read_csv(dev_path)\n",
    "print(f\"\\nDev data shape: {dev_df.shape}\")\n",
    "print(f\"Number of unique clusters in dev: {dev_df['cluster'].nunique()}\")\n",
    "print(f\"Number of terms in dev: {len(dev_df)}\")\n",
    "\n",
    "# Create term-to-cluster mapping\n",
    "term_to_cluster = dict(zip(train_df['term'].str.lower(), train_df['cluster']))\n",
    "\n",
    "# Create cluster-to-terms mapping for analysis\n",
    "cluster_to_terms = defaultdict(list)\n",
    "for term, cluster in term_to_cluster.items():\n",
    "    cluster_to_terms[cluster].append(term)\n",
    "\n",
    "print(f\"\\nExample clusters from training:\")\n",
    "for cluster_id in sorted(cluster_to_terms.keys())[:5]:\n",
    "    print(f\"  Cluster {cluster_id}: {cluster_to_terms[cluster_id]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5170207f",
   "metadata": {},
   "source": [
    "## Text Normalization Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eba1b97f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original: La raccolta differenziata è importante!\n",
      "Normalized: la raccolta differenziata è importante\n",
      "Tokens: ['la', 'raccolta', 'differenziata', 'è', 'importante']\n"
     ]
    }
   ],
   "source": [
    "def normalize_text(text: str) -> str:\n",
    "    \"\"\"Lowercase, remove punctuation, normalize whitespace.\"\"\"\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^\\w\\sÀ-ÖØ-öø-ÿ]+\", \" \", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text\n",
    "\n",
    "\n",
    "def tokenize_text(text: str) -> List[str]:\n",
    "    \"\"\"Tokenize text using NLTK.\"\"\"\n",
    "    try:\n",
    "        return word_tokenize(text, language='italian')\n",
    "    except:\n",
    "        return text.split()\n",
    "\n",
    "\n",
    "# Test\n",
    "test_text = \"La raccolta differenziata è importante!\"\n",
    "print(f\"Original: {test_text}\")\n",
    "print(f\"Normalized: {normalize_text(test_text)}\")\n",
    "print(f\"Tokens: {tokenize_text(normalize_text(test_text))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d12f7b",
   "metadata": {},
   "source": [
    "## Baseline: String Similarity Clustering\n",
    "\n",
    "Uses fuzzy string matching to find the most similar training term for each dev term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8365dc40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building term index...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built index with 3 terms\n",
      "\n",
      " Baseline model works!!\n",
      "  'spazzatura' -> Cluster -1 (similarity: 0.107)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "class NLTKBaselineClustering:\n",
    "    \"\"\"Baseline clustering using string similarity.\"\"\"\n",
    "    \n",
    "    def __init__(self, similarity_threshold=0.6):\n",
    "        self.similarity_threshold = similarity_threshold\n",
    "        self.term_to_cluster = {}\n",
    "        self.normalized_terms = {}\n",
    "    \n",
    "    def fit(self, terms: List[str], clusters: List[int]):\n",
    "        \"\"\"Build term-cluster mapping.\"\"\"\n",
    "        print(\"Building term index...\")\n",
    "        for term, cluster in tqdm(zip(terms, clusters), total=len(terms)):\n",
    "            term_lower = term.lower()\n",
    "            norm_term = normalize_text(term_lower)\n",
    "            self.term_to_cluster[term_lower] = cluster\n",
    "            self.normalized_terms[term_lower] = norm_term\n",
    "        \n",
    "        print(f\"Built index with {len(self.term_to_cluster)} terms\")\n",
    "    \n",
    "    def _compute_similarity(self, term1: str, term2: str) -> float:\n",
    "        \"\"\"Compute string similarity using multiple methods.\"\"\"\n",
    "        norm1 = normalize_text(term1.lower())\n",
    "        norm2 = normalize_text(term2.lower())\n",
    "        \n",
    "        # Exact match\n",
    "        if norm1 == norm2:\n",
    "            return 1.0\n",
    "        \n",
    "        # Substring match\n",
    "        if norm1 in norm2 or norm2 in norm1:\n",
    "            return 0.9\n",
    "        \n",
    "        # Token overlap (Jaccard)\n",
    "        tokens1 = set(norm1.split())\n",
    "        tokens2 = set(norm2.split())\n",
    "        if tokens1 and tokens2:\n",
    "            jaccard = len(tokens1 & tokens2) / len(tokens1 | tokens2)\n",
    "        else:\n",
    "            jaccard = 0.0\n",
    "        \n",
    "        # Sequence similarity (difflib)\n",
    "        seq_sim = difflib.SequenceMatcher(None, norm1, norm2).ratio()\n",
    "        \n",
    "        # Combined score\n",
    "        return 0.6 * jaccard + 0.4 * seq_sim\n",
    "    \n",
    "    def predict_one(self, term: str) -> Tuple[int, float]:\n",
    "        \"\"\"Predict cluster for a single term.\"\"\"\n",
    "        term_lower = term.lower()\n",
    "        \n",
    "        # Check for exact match\n",
    "        if term_lower in self.term_to_cluster:\n",
    "            return self.term_to_cluster[term_lower], 1.0\n",
    "        \n",
    "        # Find most similar term\n",
    "        best_similarity = 0.0\n",
    "        best_cluster = -1\n",
    "        \n",
    "        for train_term in self.term_to_cluster.keys():\n",
    "            sim = self._compute_similarity(term_lower, train_term)\n",
    "            if sim > best_similarity:\n",
    "                best_similarity = sim\n",
    "                best_cluster = self.term_to_cluster[train_term]\n",
    "        \n",
    "        # Check threshold\n",
    "        if best_similarity < self.similarity_threshold:\n",
    "            return -1, best_similarity\n",
    "        \n",
    "        return best_cluster, best_similarity\n",
    "    \n",
    "    def predict(self, terms: List[str]) -> Tuple[List[int], List[float]]:\n",
    "        \"\"\"Predict clusters for multiple terms.\"\"\"\n",
    "        predictions = []\n",
    "        similarities = []\n",
    "        \n",
    "        for term in tqdm(terms, desc=\"Predicting clusters\"):\n",
    "            cluster, sim = self.predict_one(term)\n",
    "            predictions.append(cluster)\n",
    "            similarities.append(sim)\n",
    "        \n",
    "        return predictions, similarities\n",
    "    \n",
    "    def save(self, path: str):\n",
    "        \"\"\"Save model to disk.\"\"\"\n",
    "        os.makedirs(os.path.dirname(path) or '.', exist_ok=True)\n",
    "        model_data = {\n",
    "            'similarity_threshold': self.similarity_threshold,\n",
    "            'term_to_cluster': self.term_to_cluster,\n",
    "            'normalized_terms': self.normalized_terms\n",
    "        }\n",
    "        with open(path, 'wb') as f:\n",
    "            pickle.dump(model_data, f)\n",
    "        print(f\"Model saved to {path}\")\n",
    "    \n",
    "    def load(self, path: str):\n",
    "        \"\"\"Load model from disk.\"\"\"\n",
    "        with open(path, 'rb') as f:\n",
    "            model_data = pickle.load(f)\n",
    "        self.similarity_threshold = model_data['similarity_threshold']\n",
    "        self.term_to_cluster = model_data['term_to_cluster']\n",
    "        self.normalized_terms = model_data['normalized_terms']\n",
    "        print(f\"Model loaded from {path}\")\n",
    "\n",
    "\n",
    "# Test\n",
    "test_model = NLTKBaselineClustering(similarity_threshold=0.5)\n",
    "test_terms_list = ['rifiuti', 'carta', 'plastica']\n",
    "test_clusters_list = [37, 74, 43]\n",
    "test_model.fit(test_terms_list, test_clusters_list)\n",
    "\n",
    "pred_cluster, pred_sim = test_model.predict_one('spazzatura')\n",
    "print(f\"\\n Baseline model works!!\")\n",
    "print(f\"  'spazzatura' -> Cluster {pred_cluster} (similarity: {pred_sim:.3f})\")\n",
    "\n",
    "#pred_cluster, pred_sim = test_model.predict_one('immondizia')\n",
    "#print(f\"\\n Baseline model works!!\")\n",
    "#print(f\"  'immondizia' -> Cluster {pred_cluster} (similarity: {pred_sim:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79ea16d",
   "metadata": {},
   "source": [
    "### Train and Evaluate Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "97930c1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building term index...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 713/713 [00:00<00:00, 356738.49it/s]\n",
      "100%|██████████| 713/713 [00:00<00:00, 356738.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Built index with 713 terms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting clusters: 100%|██████████| 242/242 [00:02<00:00, 97.55it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction statistics:\n",
      "  Total terms: 242\n",
      "  Terms with exact match: 140\n",
      "  Terms with high similarity (≥0.8): 78\n",
      "  Terms with medium similarity (0.6-0.8): 1\n",
      "  Terms below threshold (unknown): 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize baseline model\n",
    "baseline_model = NLTKBaselineClustering(similarity_threshold=0.6)\n",
    "\n",
    "# Fit on training data\n",
    "baseline_model.fit(train_df['term'].tolist(), train_df['cluster'].tolist())\n",
    "\n",
    "# Predict on dev set\n",
    "baseline_preds, baseline_sims = baseline_model.predict(dev_df['term'].tolist())\n",
    "\n",
    "# Store results\n",
    "dev_df['baseline_cluster'] = baseline_preds\n",
    "dev_df['baseline_similarity'] = baseline_sims\n",
    "\n",
    "print(f\"\\nPrediction statistics:\")\n",
    "print(f\"  Total terms: {len(baseline_preds)}\")\n",
    "print(f\"  Terms with exact match: {sum(1 for s in baseline_sims if s >= 0.99)}\")\n",
    "print(f\"  Terms with high similarity (≥0.8): {sum(1 for s in baseline_sims if 0.8 <= s < 0.99)}\")\n",
    "print(f\"  Terms with medium similarity (0.6-0.8): {sum(1 for s in baseline_sims if 0.6 <= s < 0.8)}\")\n",
    "print(f\"  Terms below threshold (unknown): {sum(1 for p in baseline_preds if p == -1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccaa238d",
   "metadata": {},
   "source": [
    "## Save Models and Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0018bcce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to models/nltk_clustering_baseline.pkl\n",
      "\n",
      "Baseline predictions saved to predictions/subtask_b_dev_nltk_baseline_preds.csv\n"
     ]
    }
   ],
   "source": [
    "# Save baseline model\n",
    "baseline_model.save('models/nltk_clustering_baseline.pkl')\n",
    "\n",
    "# Save predictions\n",
    "output_path_baseline = \"predictions/subtask_b_dev_nltk_baseline_preds.csv\"\n",
    "#dev_df[['term', 'baseline_cluster', 'baseline_similarity']].to_csv(output_path_baseline, index=False)\n",
    "dev_df[['term', 'baseline_cluster']].to_csv(output_path_baseline, index=False)\n",
    "print(f\"\\nBaseline predictions saved to {output_path_baseline}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8f0c92",
   "metadata": {},
   "source": [
    "### Evaluate Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "17ed1220",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import codecs\n",
    "import json\n",
    "from collections import defaultdict\n",
    "\n",
    "def load_data(file_path):\n",
    "  \"\"\"\n",
    "  Loads data from a CSV or JSON file and returns a dictionary\n",
    "  where keys are terms and values are cluster_ids.\n",
    "\n",
    "  Args:\n",
    "    file_path: The path to the input file (CSV or JSON).\n",
    "\n",
    "  Returns:\n",
    "    A dictionary containing the loaded data.\n",
    "\n",
    "  Raises:\n",
    "    ValueError: If the file format is not supported.\n",
    "  \"\"\"\n",
    "  if file_path.endswith('.csv'):\n",
    "    # Load data from CSV file\n",
    "    df = pd.read_csv(file_path)\n",
    "    data = {term: int(cluster) for term, cluster in df.itertuples(index=False)}\n",
    "  elif file_path.endswith('.json'):\n",
    "    # Load data from JSON file\n",
    "    with codecs.open(file_path, 'r', 'utf-8') as f:\n",
    "      json_data = json.load(f)\n",
    "    # Extract terms from JSON data\n",
    "    data = {item[\"term\"]: item[\"cluster\"] for item in json_data[\"data\"]}\n",
    "  else:\n",
    "    # Raise error for unsupported file formats\n",
    "    raise ValueError(\"Unsupported file format. Only CSV and JSON files are supported.\")\n",
    "  return data\n",
    "\n",
    "class BCubed_calculator:\n",
    "  def __init__(self, gold, pred):\n",
    "    self.gold = gold\n",
    "    self.pred = pred\n",
    "    self.gold_cluster = defaultdict(set)\n",
    "    self.pred_cluster = defaultdict(set)\n",
    "    for item, clus_id in gold.items():\n",
    "        self.gold_cluster[clus_id].add(item)\n",
    "    for item, clus_id in pred.items():\n",
    "      self.pred_cluster[clus_id].add(item)\n",
    "\n",
    "  def bc_precision_item(self, item):\n",
    "    pred_id = self.pred[item]\n",
    "    gold_id = self.gold.get(item, None)\n",
    "    TP = len(self.pred_cluster[pred_id].intersection(self.gold_cluster[gold_id]))\n",
    "    FP = len(self.pred_cluster[pred_id]) - TP\n",
    "    return TP/(FP + TP)\n",
    "\n",
    "  def bc_recall_item(self, item):\n",
    "    pred_id = self.pred.get(item, None)\n",
    "    gold_id = self.gold.get(item)\n",
    "    TP = len(self.pred_cluster[pred_id].intersection(self.gold_cluster[gold_id]))\n",
    "    FN = len(self.gold_cluster[gold_id]) - TP\n",
    "    return TP/(TP + FN)\n",
    "\n",
    "def bcubed_precision(gold, pred):\n",
    "  calc = BCubed_calculator(gold, pred)\n",
    "  return np.average([calc.bc_precision_item(item) for item in calc.pred])\n",
    "\n",
    "def bcubed_recall(gold, pred):\n",
    "  calc = BCubed_calculator(gold, pred)\n",
    "  return np.average([calc.bc_recall_item(item) for item in calc.gold])\n",
    "\n",
    "def bcubed_f1(gold, pred):\n",
    "  return 2 * bcubed_precision(gold, pred) * bcubed_recall(gold, pred) / (bcubed_precision(gold, pred) + bcubed_recall(gold, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "71653e46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BCubed Precision: 0.6341\n",
      "BCubed Recall: 0.8607\n",
      "BCubed F1: 0.7302\n"
     ]
    }
   ],
   "source": [
    "preds = load_data(\"predictions/subtask_b_dev_nltk_baseline_preds.csv\")\n",
    "gold = load_data(\"../data/subtask_b_dev.csv\")\n",
    "print(f\"BCubed Precision: {bcubed_precision(gold, preds):.4f}\")\n",
    "print(f\"BCubed Recall: {bcubed_recall(gold, preds):.4f}\")\n",
    "print(f\"BCubed F1: {bcubed_f1(gold, preds):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31ca25e2",
   "metadata": {},
   "source": [
    "## TF-IDF Based Clustering\n",
    "\n",
    "Uses TF-IDF vectorization to compute semantic similarity between terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f74493a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building TF-IDF vectors...\n",
      "Built TF-IDF index with 3 terms\n",
      "Vector shape: (3, 40)\n",
      "\n",
      " TF-IDF model works!!\n",
      "  'spazzatura' -> Cluster -1 (similarity: 0.000)\n"
     ]
    }
   ],
   "source": [
    "class NLTKTfidfClustering:\n",
    "    \"\"\"TF-IDF based clustering.\"\"\"\n",
    "    \n",
    "    def __init__(self, similarity_threshold=0.3):\n",
    "        self.similarity_threshold = similarity_threshold\n",
    "        self.vectorizer = None\n",
    "        self.term_vectors = None\n",
    "        self.term_to_cluster = {}\n",
    "        self.train_terms = []\n",
    "    \n",
    "    def fit(self, terms: List[str], clusters: List[int]):\n",
    "        \"\"\"Build TF-IDF vectors for training terms.\"\"\"\n",
    "        print(\"Building TF-IDF vectors...\")\n",
    "        \n",
    "        # Normalize and store terms\n",
    "        self.train_terms = [t.lower() for t in terms]\n",
    "        normalized_terms = [normalize_text(t) for t in self.train_terms]\n",
    "        \n",
    "        # Build term-cluster mapping\n",
    "        for term, cluster in zip(self.train_terms, clusters):\n",
    "            self.term_to_cluster[term] = cluster\n",
    "        \n",
    "        # Create TF-IDF vectors\n",
    "        # Use character n-grams to capture subword information\n",
    "        self.vectorizer = TfidfVectorizer(\n",
    "            analyzer='char',\n",
    "            ngram_range=(2, 4),\n",
    "            lowercase=True,\n",
    "            max_features=5000\n",
    "        )\n",
    "        \n",
    "        self.term_vectors = self.vectorizer.fit_transform(normalized_terms)\n",
    "        \n",
    "        print(f\"Built TF-IDF index with {len(self.train_terms)} terms\")\n",
    "        print(f\"Vector shape: {self.term_vectors.shape}\")\n",
    "    \n",
    "    def predict_one(self, term: str) -> Tuple[int, float]:\n",
    "        \"\"\"Predict cluster for a single term.\"\"\"\n",
    "        term_lower = term.lower()\n",
    "        \n",
    "        # Check for exact match\n",
    "        if term_lower in self.term_to_cluster:\n",
    "            return self.term_to_cluster[term_lower], 1.0\n",
    "        \n",
    "        # Compute TF-IDF vector for query term\n",
    "        norm_term = normalize_text(term_lower)\n",
    "        query_vec = self.vectorizer.transform([norm_term])\n",
    "        \n",
    "        # Compute cosine similarity with all training terms\n",
    "        similarities = cosine_similarity(query_vec, self.term_vectors)[0]\n",
    "        \n",
    "        # Find most similar term\n",
    "        best_idx = np.argmax(similarities)\n",
    "        best_similarity = similarities[best_idx]\n",
    "        \n",
    "        # Check threshold\n",
    "        if best_similarity < self.similarity_threshold:\n",
    "            return -1, best_similarity\n",
    "        \n",
    "        best_term = self.train_terms[best_idx]\n",
    "        best_cluster = self.term_to_cluster[best_term]\n",
    "        \n",
    "        return best_cluster, best_similarity\n",
    "    \n",
    "    def predict(self, terms: List[str]) -> Tuple[List[int], List[float]]:\n",
    "        \"\"\"Predict clusters for multiple terms.\"\"\"\n",
    "        predictions = []\n",
    "        similarities = []\n",
    "        \n",
    "        for term in tqdm(terms, desc=\"Predicting clusters\"):\n",
    "            cluster, sim = self.predict_one(term)\n",
    "            predictions.append(cluster)\n",
    "            similarities.append(sim)\n",
    "        \n",
    "        return predictions, similarities\n",
    "    \n",
    "    def save(self, path: str):\n",
    "        \"\"\"Save model to disk.\"\"\"\n",
    "        os.makedirs(os.path.dirname(path) or '.', exist_ok=True)\n",
    "        model_data = {\n",
    "            'similarity_threshold': self.similarity_threshold,\n",
    "            'vectorizer': self.vectorizer,\n",
    "            'term_vectors': self.term_vectors,\n",
    "            'term_to_cluster': self.term_to_cluster,\n",
    "            'train_terms': self.train_terms\n",
    "        }\n",
    "        with open(path, 'wb') as f:\n",
    "            pickle.dump(model_data, f)\n",
    "        print(f\"Model saved to {path}\")\n",
    "    \n",
    "    def load(self, path: str):\n",
    "        \"\"\"Load model from disk.\"\"\"\n",
    "        with open(path, 'rb') as f:\n",
    "            model_data = pickle.load(f)\n",
    "        self.similarity_threshold = model_data['similarity_threshold']\n",
    "        self.vectorizer = model_data['vectorizer']\n",
    "        self.term_vectors = model_data['term_vectors']\n",
    "        self.term_to_cluster = model_data['term_to_cluster']\n",
    "        self.train_terms = model_data['train_terms']\n",
    "        print(f\"Model loaded from {path}\")\n",
    "\n",
    "\n",
    "# Test\n",
    "test_tfidf = NLTKTfidfClustering(similarity_threshold=0.1)\n",
    "test_tfidf.fit(['rifiuti', 'carta', 'plastica'], [37, 74, 43])\n",
    "pred_cluster, pred_sim = test_tfidf.predict_one('spazzatura')\n",
    "print(f\"\\n TF-IDF model works!!\")\n",
    "print(f\"  'spazzatura' -> Cluster {pred_cluster} (similarity: {pred_sim:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf83102a",
   "metadata": {},
   "source": [
    "### Train and Evaluate TF-IDF Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e614d832",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building TF-IDF vectors...\n",
      "Built TF-IDF index with 713 terms\n",
      "Vector shape: (713, 4146)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting clusters: 100%|██████████| 242/242 [00:00<00:00, 2024.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prediction statistics:\n",
      "  Total terms: 242\n",
      "  Terms with exact match: 140\n",
      "  Terms with high similarity (≥0.6): 58\n",
      "  Terms with medium similarity (0.3-0.6): 30\n",
      "  Terms below threshold (unknown): 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Initialize TF-IDF model\n",
    "tfidf_model = NLTKTfidfClustering(similarity_threshold=0.3)\n",
    "\n",
    "# Fit on training data\n",
    "tfidf_model.fit(train_df['term'].tolist(), train_df['cluster'].tolist())\n",
    "\n",
    "# Predict on dev set\n",
    "tfidf_preds, tfidf_sims = tfidf_model.predict(dev_df['term'].tolist())\n",
    "\n",
    "# Store results\n",
    "dev_df['tfidf_cluster'] = tfidf_preds\n",
    "dev_df['tfidf_similarity'] = tfidf_sims\n",
    "\n",
    "print(f\"\\nPrediction statistics:\")\n",
    "print(f\"  Total terms: {len(tfidf_preds)}\")\n",
    "print(f\"  Terms with exact match: {sum(1 for s in tfidf_sims if s >= 0.99)}\")\n",
    "print(f\"  Terms with high similarity (≥0.6): {sum(1 for s in tfidf_sims if 0.6 <= s < 0.99)}\")\n",
    "print(f\"  Terms with medium similarity (0.3-0.6): {sum(1 for s in tfidf_sims if 0.3 <= s < 0.6)}\")\n",
    "print(f\"  Terms below threshold (unknown): {sum(1 for p in tfidf_preds if p == -1)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003d7d00",
   "metadata": {},
   "source": [
    "## Save Models and Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29431cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to models/nltk_clustering_baseline.pkl\n",
      "Model saved to models/nltk_clustering_tfidf.pkl\n",
      "\n",
      "Baseline predictions saved to predictions/subtask_b_dev_nltk_baseline_preds.csv\n",
      "TF-IDF predictions saved to predictions/subtask_b_dev_nltk_tfidf_preds.csv\n"
     ]
    }
   ],
   "source": [
    "# Save TF-IDF model\n",
    "tfidf_model.save('models/nltk_clustering_tfidf.pkl')\n",
    "\n",
    "# Save predictions\n",
    "output_path_tfidf = \"predictions/subtask_b_dev_nltk_tfidf_preds.csv\"\n",
    "#dev_df[['term', 'tfidf_cluster', 'tfidf_similarity']].to_csv(output_path_tfidf, index=False)\n",
    "dev_df[['term', 'tfidf_cluster']].to_csv(output_path_tfidf, index=False)\n",
    "print(f\"TF-IDF predictions saved to {output_path_tfidf}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e4454b",
   "metadata": {},
   "source": [
    "### Evaluate TF-IDF Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "40f89364",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BCubed Precision: 0.8002\n",
      "BCubed Recall: 0.9406\n",
      "BCubed F1: 0.8647\n"
     ]
    }
   ],
   "source": [
    "preds = load_data(\"predictions/subtask_b_dev_nltk_tfidf_preds.csv\")\n",
    "gold = load_data(\"../data/subtask_b_dev.csv\")\n",
    "print(f\"BCubed Precision: {bcubed_precision(gold, preds):.4f}\")\n",
    "print(f\"BCubed Recall: {bcubed_recall(gold, preds):.4f}\")\n",
    "print(f\"BCubed F1: {bcubed_f1(gold, preds):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed31ab2",
   "metadata": {},
   "source": [
    "## Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9d89b1b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "MODEL COMPARISON - BCubed Metrics\n",
      "================================================================================\n",
      "                Model  BCubed Precision  BCubed Recall  BCubed F1\n",
      "Baseline (Similarity)          0.634102       0.860685   0.730220\n",
      "    TF-IDF Similarity          0.800207       0.940575   0.864731\n",
      "================================================================================\n",
      "\n",
      "TF-IDF vs Baseline:\n",
      "  BCubed Precision improvement: +26.2%\n",
      "  BCubed Recall improvement: +9.3%\n",
      "  BCubed F1 improvement: +18.4%\n"
     ]
    }
   ],
   "source": [
    "# Load predictions and gold standard for both models\n",
    "gold = load_data(\"../data/subtask_b_dev.csv\")\n",
    "baseline_preds = load_data(\"predictions/subtask_b_dev_nltk_baseline_preds.csv\")\n",
    "tfidf_preds = load_data(\"predictions/subtask_b_dev_nltk_tfidf_preds.csv\")\n",
    "\n",
    "# Compute BCubed metrics for baseline model\n",
    "baseline_precision = bcubed_precision(gold, baseline_preds)\n",
    "baseline_recall = bcubed_recall(gold, baseline_preds)\n",
    "baseline_f1 = bcubed_f1(gold, baseline_preds)\n",
    "\n",
    "# Compute BCubed metrics for TF-IDF model\n",
    "tfidf_precision = bcubed_precision(gold, tfidf_preds)\n",
    "tfidf_recall = bcubed_recall(gold, tfidf_preds)\n",
    "tfidf_f1 = bcubed_f1(gold, tfidf_preds)\n",
    "\n",
    "# Create comparison dataframe\n",
    "comparison_df = pd.DataFrame([\n",
    "    {\n",
    "        'Model': 'Baseline (Similarity)',\n",
    "        'BCubed Precision': baseline_precision,\n",
    "        'BCubed Recall': baseline_recall,\n",
    "        'BCubed F1': baseline_f1\n",
    "    },\n",
    "    {\n",
    "        'Model': 'TF-IDF Similarity',\n",
    "        'BCubed Precision': tfidf_precision,\n",
    "        'BCubed Recall': tfidf_recall,\n",
    "        'BCubed F1': tfidf_f1\n",
    "    }\n",
    "])\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MODEL COMPARISON - BCubed Metrics\")\n",
    "print(\"=\"*80)\n",
    "print(comparison_df.to_string(index=False))\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Calculate improvements\n",
    "precision_improvement = (tfidf_precision - baseline_precision) / baseline_precision * 100 if baseline_precision > 0 else 0\n",
    "recall_improvement = (tfidf_recall - baseline_recall) / baseline_recall * 100 if baseline_recall > 0 else 0\n",
    "f1_improvement = (tfidf_f1 - baseline_f1) / baseline_f1 * 100 if baseline_f1 > 0 else 0\n",
    "\n",
    "print(f\"\\nTF-IDF vs Baseline:\")\n",
    "print(f\"  BCubed Precision improvement: {precision_improvement:+.1f}%\")\n",
    "print(f\"  BCubed Recall improvement: {recall_improvement:+.1f}%\")\n",
    "print(f\"  BCubed F1 improvement: {f1_improvement:+.1f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ate-it",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
